# 上下文长度优化 - 实施任务列表

## 任务概述

本任务列表将上下文长度优化方案分解为可执行的开发任务。任务按优先级和依赖关系组织，支持渐进式实施。

---

## Phase 1: 立即修复与基础设施 (高优先级)

### - [ ] 1. 创建模型适配层

创建统一的模型参数管理和验证机制。

- [ ] 1.1 创建 ModelAdapter 类
  - 在 `src/model_adapter.py` 创建新文件
  - 实现 `MODEL_LIMITS` 配置字典，包含 DeepSeek 和 OpenAI 模型限制
  - 实现 `get_model_limits(model: str)` 方法
  - 实现 `validate_and_adjust_params(model: str, **kwargs)` 方法
  - 添加日志记录参数调整操作
  - _需求: 1.1, 1.2, 1.3_

- [ ] 1.2 实现安全 API 调用方法
  - 在 ModelAdapter 中实现 `safe_api_call()` 方法
  - 集成参数验证和调整逻辑
  - 实现参数错误的自动重试机制（最多2次）
  - 添加详细的错误日志
  - _需求: 1.1, 1.5, 4.2_

- [ ]* 1.3 编写 ModelAdapter 单元测试
  - 创建 `tests/test_model_adapter.py`
  - 测试不同模型的参数限制获取
  - 测试参数验证和调整逻辑
  - 测试边界情况（超大值、负值、None）
  - _需求: 9.1_

### - [ ] 2. 修复现有 Agent 的参数问题

立即修复 Writer 和 Editor Agent 的 max_tokens 问题。

- [ ] 2.1 修改 Writer Agent
  - 在 `src/agents.py` 中修改 `writer_agent()` 函数
  - 将直接 API 调用替换为 `ModelAdapter.safe_api_call()`
  - 移除硬编码的 `max_tokens=15000`，改为动态获取
  - 保持函数签名不变（向后兼容）
  - _需求: 1.1, 1.2, 7.1_

- [ ] 2.2 修改 Editor Agent
  - 在 `src/agents.py` 中修改 `editor_agent()` 函数
  - 将直接 API 调用替换为 `ModelAdapter.safe_api_call()`
  - 显式设置 `max_tokens` 参数
  - 保持函数签名不变（向后兼容）
  - _需求: 1.1, 1.2, 7.1_

- [ ] 2.3 修改 Research Agent
  - 在 `src/agents.py` 中修改 `research_agent()` 函数
  - 将直接 API 调用替换为 `ModelAdapter.safe_api_call()`
  - 确保参数符合模型限制
  - _需求: 1.1, 1.2_

- [ ]* 2.4 验证修复效果
  - 运行 `test_system.py` 验证所有 Agent 正常工作
  - 测试使用 DeepSeek 模型的完整流程
  - 测试使用 OpenAI 模型的完整流程
  - 确认不再出现 max_tokens 错误
  - _需求: 4.5, 9.2_

### - [ ] 3. 增强降级机制

改进错误处理和模型降级逻辑。

- [ ] 3.1 创建增强的降级装饰器
  - 在 `src/fallback.py` 中创建 `enhanced_fallback()` 装饰器
  - 实现错误类型识别（参数错误、速率限制、模型错误）
  - 实现参数错误的自动调整和重试
  - 实现模型降级逻辑
  - 添加详细的日志记录
  - _需求: 4.1, 4.2, 4.3, 4.4_

- [ ] 3.2 应用增强降级到所有 Agent
  - 将 `@with_fallback` 替换为 `@enhanced_fallback`
  - 确保所有 Agent 都受保护
  - 测试降级机制是否正常工作
  - _需求: 4.2, 4.3_

- [ ]* 3.3 编写降级机制测试
  - 创建 `tests/test_fallback.py`
  - 模拟参数错误，验证自动调整
  - 模拟模型失败，验证降级逻辑
  - 验证重试次数限制
  - _需求: 9.2, 9.4_

### - [ ] 4. 添加 Token 使用监控

实现 token 使用的统计和监控。

- [ ] 4.1 创建 TokenUsageStats 数据类
  - 在 `src/monitoring.py` 创建新文件
  - 实现 `TokenUsageStats` dataclass
  - 实现 `to_dict()` 方法用于序列化
  - 实现上下文窗口使用率计算
  - _需求: 5.1, 5.2_

- [ ] 4.2 集成 token 统计到 Agent 调用
  - 在 ModelAdapter 的 `safe_api_call()` 中收集统计
  - 记录每次调用的 input/output tokens
  - 计算上下文窗口使用率
  - 当使用率超过 90% 时记录警告
  - _需求: 5.1, 5.2, 5.3_

- [ ] 4.3 实现统计报告功能
  - 实现 `generate_usage_report()` 函数
  - 在任务完成后生成报告
  - 包含总 token 使用、平均使用率、成本估算
  - _需求: 5.4, 5.5_

- [ ]* 4.4 添加监控测试
  - 测试统计数据收集
  - 测试报告生成
  - 验证警告触发逻辑
  - _需求: 9.1_

---

## Phase 2: 分块处理实现 (中优先级)

### - [ ] 5. 实现分块处理器

创建处理长文本的分块机制。

- [ ] 5.1 创建 ChunkingProcessor 类
  - 在 `src/chunking.py` 创建新文件
  - 实现 `chunk_by_semantic()` 方法，按段落分块
  - 实现 `_split_long_paragraph()` 处理超长段落
  - 支持可配置的块大小和重叠
  - _需求: 2.2, 2.3_

- [ ] 5.2 实现上下文保持机制
  - 实现 `process_with_context()` 方法
  - 为每个块提供前后文本信息
  - 实现 `_build_chunk_prompt()` 构建带上下文的提示
  - 确保块间连贯性
  - _需求: 2.3, 2.4_

- [ ] 5.3 实现块合并逻辑
  - 实现 `merge_chunks()` 方法
  - 简单拼接作为初始实现
  - 处理块间的过渡
  - _需求: 2.4_

- [ ]* 5.4 编写分块处理器测试
  - 创建 `tests/test_chunking.py`
  - 测试不同长度文本的分块
  - 测试语义边界识别
  - 测试重叠区域处理
  - 测试合并逻辑
  - _需求: 9.2, 9.3_

### - [ ] 6. 创建上下文管理器

实现智能决策处理策略的管理器。

- [ ] 6.1 创建 ContextManager 类
  - 在 `src/context_manager.py` 创建新文件
  - 实现 `should_chunk()` 判断是否需要分块
  - 实现 `should_compress()` 判断是否需要压缩
  - 集成 ModelAdapter 获取模型限制
  - _需求: 2.1_

- [ ] 6.2 实现智能处理方法
  - 实现 `process_text()` 方法
  - 根据文本长度自动选择策略（直接/分块）
  - 集成 ChunkingProcessor
  - 添加进度日志
  - _需求: 2.1, 2.5_

- [ ]* 6.3 编写上下文管理器测试
  - 创建 `tests/test_context_manager.py`
  - 测试策略决策逻辑
  - 测试不同长度文本的处理
  - 验证正确调用分块处理器
  - _需求: 9.2_

### - [ ] 7. 集成分块处理到 Agent

将分块处理能力集成到现有 Agent。

- [ ] 7.1 创建分块版本的 Editor Agent
  - 在 `src/agents.py` 中创建 `editor_agent_chunked()` 函数
  - 使用 ContextManager 判断是否需要分块
  - 集成 ChunkingProcessor 处理长文本
  - 保持原 `editor_agent()` 不变（向后兼容）
  - _需求: 2.1, 2.2, 2.3, 2.4, 7.1_

- [ ] 7.2 更新 executor 使用分块版本
  - 在 `src/planning_agent.py` 中修改 `executor_agent_step()`
  - 对 Editor Agent 使用分块版本
  - 添加配置开关控制是否启用分块
  - _需求: 6.3, 7.3_

- [ ]* 7.3 端到端测试分块处理
  - 创建包含长文本的测试用例
  - 验证分块处理的完整流程
  - 验证输出质量和连贯性
  - 测量处理时间
  - _需求: 8.1, 9.2, 9.3_

### - [ ] 8. 添加配置管理

实现灵活的配置系统。

- [ ] 8.1 创建配置数据类
  - 在 `src/config.py` 中添加 `ContextProcessingConfig` dataclass
  - 定义所有可配置参数（分块阈值、重叠大小等）
  - 实现 `from_env()` 从环境变量加载
  - 实现配置验证
  - _需求: 6.1, 6.2, 6.4, 6.5_

- [ ] 8.2 集成配置到组件
  - 在 ContextManager 中使用配置
  - 在 ChunkingProcessor 中使用配置
  - 支持运行时配置更新
  - _需求: 6.1, 6.2_

- [ ] 8.3 更新环境变量文档
  - 在 `.env.example` 中添加新配置项
  - 在 README 中添加配置说明
  - 提供配置示例和最佳实践
  - _需求: 10.3_

---

## Phase 3: 摘要压缩 (低优先级)

### - [ ] 9. 实现摘要压缩器

创建智能压缩历史上下文的机制。

- [ ] 9.1 创建 SummarizationCompressor 类
  - 在 `src/summarization.py` 创建新文件
  - 实现 `compress()` 方法
  - 实现 `_generate_structured_summary()` 生成结构化摘要
  - 实现 `_structured_to_text()` 转换为文本
  - 实现缓存机制
  - _需求: 3.1, 3.2, 3.3, 3.5_

- [ ] 9.2 实现递归压缩
  - 实现 `compress_recursive()` 处理超长文本
  - 支持多层压缩
  - 控制压缩比例
  - _需求: 3.4_

- [ ]* 9.3 编写压缩器测试
  - 创建 `tests/test_summarization.py`
  - 测试结构化提取
  - 测试压缩比例控制
  - 测试缓存机制
  - _需求: 9.1_

### - [ ] 10. 集成摘要到数据流

在 Agent 间传递时自动压缩数据。

- [ ] 10.1 创建 AgentPipeline 类
  - 在 `src/pipeline.py` 创建新文件
  - 实现 Research → Writer 流程，带摘要
  - 实现 Writer → Editor 流程，带摘要
  - 缓存完整数据和摘要
  - _需求: 3.1, 3.5_

- [ ] 10.2 更新 executor 使用 pipeline
  - 在 `src/planning_agent.py` 中集成 AgentPipeline
  - 添加配置开关控制是否启用压缩
  - 保持向后兼容
  - _需求: 6.3, 7.3_

- [ ]* 10.3 测试摘要集成
  - 验证摘要生成质量
  - 验证信息保留程度
  - 测量压缩效果和成本
  - _需求: 9.2_

---

## Phase 4: 文档与优化 (持续)

### - [ ] 11. 完善文档

创建完整的使用和维护文档。

- [ ] 11.1 编写架构文档
  - 在 `docs/architecture.md` 创建文档
  - 说明上下文管理的设计原理
  - 包含组件关系图
  - 说明数据流和决策逻辑
  - _需求: 10.1_

- [ ] 11.2 编写 API 文档
  - 为所有新增类和方法添加 docstring
  - 使用 Sphinx 生成 API 文档
  - 包含使用示例
  - _需求: 10.2_

- [ ] 11.3 编写配置指南
  - 创建 `docs/configuration.md`
  - 说明所有配置参数
  - 提供不同场景的配置示例
  - 说明性能调优建议
  - _需求: 10.3_

- [ ] 11.4 编写故障排查指南
  - 创建 `docs/troubleshooting.md`
  - 列出常见问题和解决方法
  - 包含日志分析指南
  - 提供调试技巧
  - _需求: 10.4_

### - [ ] 12. 性能优化

优化系统性能和成本。

- [ ] 12.1 实现并行处理
  - 在 ChunkingProcessor 中支持并行处理多个块
  - 使用 asyncio 或 ThreadPoolExecutor
  - 测量性能提升
  - _需求: 8.3_

- [ ] 12.2 优化缓存策略
  - 实现 LRU 缓存
  - 缓存摘要结果
  - 缓存重复查询
  - _需求: 8.4_

- [ ] 12.3 优化 token 使用
  - 移除冗余信息
  - 优化提示词
  - 智能选择相关内容
  - _需求: 8.1_

- [ ]* 12.4 性能基准测试
  - 创建性能测试套件
  - 测量不同长度文本的处理时间
  - 测量 token 使用和成本
  - 生成性能报告
  - _需求: 9.3_

### - [ ] 13. 监控和可观测性

增强系统监控能力。

- [ ] 13.1 实现详细日志
  - 为所有关键操作添加日志
  - 使用结构化日志格式
  - 支持不同日志级别
  - _需求: 5.4_

- [ ] 13.2 实现指标收集
  - 收集 token 使用指标
  - 收集性能指标（延迟、吞吐量）
  - 收集错误率指标
  - _需求: 5.1, 5.2, 5.3_

- [ ] 13.3 创建监控仪表板
  - 实现 `/metrics` API 端点
  - 返回实时统计数据
  - 支持 Prometheus 格式（可选）
  - _需求: 5.4_

---

## 验收标准

### Phase 1 完成标准
- ✅ 所有 Agent 不再出现 max_tokens 错误
- ✅ 参数自动适配不同模型
- ✅ 错误自动恢复机制工作正常
- ✅ Token 使用被正确监控和记录

### Phase 2 完成标准
- ✅ 系统能处理任意长度文本
- ✅ 分块处理保持输出连贯性
- ✅ 处理时间不超过原时间的 150%
- ✅ 配置系统灵活可用

### Phase 3 完成标准
- ✅ 摘要压缩减少 50%+ token 使用
- ✅ 关键信息保留率 > 90%
- ✅ 端到端流程集成完整

### Phase 4 完成标准
- ✅ 文档完整且易于理解
- ✅ 测试覆盖率 > 80%
- ✅ 性能满足要求
- ✅ 监控系统完善

---

## 注意事项

1. **向后兼容**: 所有修改必须保持现有 API 不变
2. **渐进式实施**: 每个 Phase 独立可用，不依赖后续 Phase
3. **充分测试**: 每个功能都需要单元测试和集成测试
4. **文档同步**: 代码修改时同步更新文档
5. **性能监控**: 持续监控性能和成本影响

## 估算工作量

- **Phase 1**: 2-3 天（立即修复）
- **Phase 2**: 3-5 天（分块处理）
- **Phase 3**: 3-4 天（摘要压缩）
- **Phase 4**: 持续进行（文档和优化）

**总计**: 约 2-3 周完整实施
