# ç”Ÿäº§çº§ AI åº”ç”¨åç«¯æ¶æ„åˆ†æ

## ğŸ¯ ChatGPT / Claude Web åº”ç”¨çš„æ¶æ„æ¨æµ‹

åŸºäºå…¬å¼€ä¿¡æ¯ã€è¡Œä¸šå®è·µå’ŒæŠ€æœ¯åšå®¢ï¼Œè¿™æ˜¯å…¸å‹çš„ç”Ÿäº§æ¶æ„ï¼š

---

## 1. æ•´ä½“æ¶æ„å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·å±‚                                â”‚
â”‚  Web App (React/Next.js) + Mobile App (React Native/Swift)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ HTTPS/WSS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CDN + è´Ÿè½½å‡è¡¡                          â”‚
â”‚         Cloudflare / AWS CloudFront + ALB/NLB               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Gateway å±‚                          â”‚
â”‚    - è®¤è¯/æˆæƒ (JWT/OAuth)                                   â”‚
â”‚    - é™æµ (Rate Limiting)                                    â”‚
â”‚    - è¯·æ±‚è·¯ç”±                                                â”‚
â”‚    - WebSocket ç®¡ç†                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨æœåŠ¡å±‚ (å¾®æœåŠ¡)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Chat API â”‚  â”‚ User Svc â”‚  â”‚ Model Svcâ”‚  â”‚ Tool Svc â”‚   â”‚
â”‚  â”‚ (FastAPI)â”‚  â”‚ (Go/Rust)â”‚  â”‚ (Python) â”‚  â”‚ (Python) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ¶ˆæ¯é˜Ÿåˆ—å±‚                              â”‚
â”‚    Kafka / RabbitMQ / AWS SQS + Redis Streams               â”‚
â”‚    - å¼‚æ­¥ä»»åŠ¡å¤„ç†                                            â”‚
â”‚    - äº‹ä»¶é©±åŠ¨æ¶æ„                                            â”‚
â”‚    - æµå¼å“åº”ç¼“å†²                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Worker å±‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ LLM Workers  â”‚  â”‚ Tool Workers â”‚  â”‚ Async Workersâ”‚     â”‚
â”‚  â”‚ (Celery/Ray) â”‚  â”‚ (Celery)     â”‚  â”‚ (Celery)     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚  â”‚  S3/Blob â”‚  â”‚ Vector DBâ”‚   â”‚
â”‚  â”‚(ä¸»æ•°æ®åº“)â”‚  â”‚ (ç¼“å­˜)   â”‚  â”‚(æ–‡ä»¶å­˜å‚¨)â”‚  â”‚(Pinecone)â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM æ¨ç†å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  è‡ªå»ºæ¨ç†é›†ç¾¤ (vLLM/TensorRT-LLM) + GPU é›†ç¾¤         â”‚  â”‚
â”‚  â”‚  æˆ– API è°ƒç”¨ (OpenAI/Anthropic/Azure OpenAI)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. æ ¸å¿ƒæŠ€æœ¯æ ˆå¯¹æ¯”

### ChatGPT (OpenAI) æ¨æµ‹æ¶æ„

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **å‰ç«¯** | React + Next.js | SSR + CSR æ··åˆ |
| **API Gateway** | è‡ªç ” (å¯èƒ½åŸºäº Nginx/Envoy) | å¤„ç†ç™¾ä¸‡çº§å¹¶å‘ |
| **ä¸»æœåŠ¡** | Python (FastAPI/Django) | å¿«é€Ÿè¿­ä»£ |
| **å®æ—¶é€šä¿¡** | WebSocket (å¯èƒ½ç”¨ Go) | æµå¼å“åº” |
| **ä»»åŠ¡é˜Ÿåˆ—** | Celery + Redis/RabbitMQ | å¼‚æ­¥ä»»åŠ¡ |
| **æ•°æ®åº“** | PostgreSQL + Redis | ä¸»ä»å¤åˆ¶ + åˆ†ç‰‡ |
| **æ–‡ä»¶å­˜å‚¨** | AWS S3 | å¯¹è¯å†å²ã€æ–‡ä»¶ä¸Šä¼  |
| **å‘é‡æ•°æ®åº“** | Pinecone / è‡ªç ” | RAG æ£€ç´¢ |
| **LLM æ¨ç†** | è‡ªå»º GPU é›†ç¾¤ (Azure) | vLLM/Triton |
| **ç›‘æ§** | Prometheus + Grafana | å®æ—¶ç›‘æ§ |
| **æ—¥å¿—** | ELK Stack / Datadog | é›†ä¸­å¼æ—¥å¿— |

### Claude (Anthropic) æ¨æµ‹æ¶æ„

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **å‰ç«¯** | React + TypeScript | ç±»ä¼¼ ChatGPT |
| **API Gateway** | AWS API Gateway / è‡ªç ” | æ‰˜ç®¡åœ¨ AWS/GCP |
| **ä¸»æœåŠ¡** | Python (FastAPI) + Rust | Rust å¤„ç†é«˜æ€§èƒ½éƒ¨åˆ† |
| **å®æ—¶é€šä¿¡** | Server-Sent Events (SSE) | æ¯” WebSocket ç®€å• |
| **ä»»åŠ¡é˜Ÿåˆ—** | AWS SQS + Lambda | Serverless æ¶æ„ |
| **æ•°æ®åº“** | PostgreSQL (AWS RDS) | æ‰˜ç®¡æ•°æ®åº“ |
| **ç¼“å­˜** | Redis (AWS ElastiCache) | æ‰˜ç®¡ç¼“å­˜ |
| **æ–‡ä»¶å­˜å‚¨** | AWS S3 | æ ‡å‡†æ–¹æ¡ˆ |
| **LLM æ¨ç†** | è‡ªå»º GPU é›†ç¾¤ (GCP/AWS) | å¯èƒ½ç”¨ JAX/PyTorch |
| **ç›‘æ§** | AWS CloudWatch + è‡ªç ” | äº‘åŸç”Ÿç›‘æ§ |

---

## 3. å…³é”®æŠ€æœ¯å†³ç­–

### 3.1 å®æ—¶é€šä¿¡æ–¹æ¡ˆ

**WebSocket vs Server-Sent Events (SSE)**

```python
# ===== æ–¹æ¡ˆ 1: WebSocket (ChatGPT å¯èƒ½ä½¿ç”¨) =====
from fastapi import WebSocket

@app.websocket("/ws/chat/{conversation_id}")
async def chat_websocket(websocket: WebSocket, conversation_id: str):
    await websocket.accept()
    
    async for message in websocket.iter_text():
        # åŒå‘é€šä¿¡
        async for chunk in stream_llm_response(message):
            await websocket.send_json({
                "type": "chunk",
                "content": chunk
            })
    
    await websocket.close()

# ä¼˜ç‚¹: åŒå‘é€šä¿¡ï¼Œå¯ä»¥ä¸­æ–­ç”Ÿæˆ
# ç¼ºç‚¹: è¿æ¥ç®¡ç†å¤æ‚ï¼Œéœ€è¦å¿ƒè·³æœºåˆ¶


# ===== æ–¹æ¡ˆ 2: Server-Sent Events (Claude å¯èƒ½ä½¿ç”¨) =====
from fastapi.responses import StreamingResponse

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def event_generator():
        async for chunk in stream_llm_response(request.message):
            yield f"data: {json.dumps({'content': chunk})}\n\n"
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )

# ä¼˜ç‚¹: ç®€å•ï¼ŒåŸºäº HTTPï¼Œè‡ªåŠ¨é‡è¿
# ç¼ºç‚¹: å•å‘é€šä¿¡ï¼ˆæœåŠ¡å™¨ â†’ å®¢æˆ·ç«¯ï¼‰
```

### 3.2 å¼‚æ­¥ä»»åŠ¡å¤„ç†

**å½“å‰é¡¹ç›® vs ç”Ÿäº§ç¯å¢ƒ**

```python
# ===== å½“å‰é¡¹ç›®: threading (ä¸é€‚åˆç”Ÿäº§) =====
import threading

def generate_report(req: PromptRequest):
    task_id = str(uuid.uuid4())
    
    # é—®é¢˜1: æ— æ³•è·¨è¿›ç¨‹/æœºå™¨
    # é—®é¢˜2: å®¹å™¨é‡å¯ä¸¢å¤±ä»»åŠ¡
    # é—®é¢˜3: æ— æ³•æ°´å¹³æ‰©å±•
    thread = threading.Thread(target=run_workflow, args=(task_id,))
    thread.start()
    
    return {"task_id": task_id}


# ===== ç”Ÿäº§ç¯å¢ƒ: Celery + Redis =====
from celery import Celery

celery_app = Celery(
    'tasks',
    broker='redis://redis:6379/0',
    backend='redis://redis:6379/1'
)

@celery_app.task(bind=True)
def run_workflow_task(self, task_id: str, prompt: str):
    """
    ä¼˜ç‚¹:
    - åˆ†å¸ƒå¼æ‰§è¡Œï¼ˆå¤šå°æœºå™¨ï¼‰
    - ä»»åŠ¡æŒä¹…åŒ–ï¼ˆRedis/RabbitMQï¼‰
    - è‡ªåŠ¨é‡è¯•
    - ä»»åŠ¡ä¼˜å…ˆçº§
    - ç›‘æ§ï¼ˆFlowerï¼‰
    """
    try:
        for step in steps:
            # æ›´æ–°è¿›åº¦
            self.update_state(
                state='PROGRESS',
                meta={'current': step, 'total': len(steps)}
            )
            
            result = execute_step(step)
        
        return {"status": "done", "result": result}
    
    except Exception as e:
        self.update_state(state='FAILURE', meta={'error': str(e)})
        raise

@app.post("/generate_report")
async def generate_report(req: ChatRequest):
    # æäº¤åˆ° Celery
    task = run_workflow_task.delay(str(uuid.uuid4()), req.prompt)
    
    return {"task_id": task.id}

@app.get("/task_status/{task_id}")
async def get_status(task_id: str):
    task = celery_app.AsyncResult(task_id)
    
    return {
        "state": task.state,
        "progress": task.info.get('current', 0) if task.state == 'PROGRESS' else None,
        "result": task.result if task.state == 'SUCCESS' else None
    }
```

### 3.3 æ•°æ®åº“æ¶æ„

**ç”Ÿäº§çº§æ•°æ®åº“è®¾è®¡**

```sql
-- ===== ä¼šè¯è¡¨ =====
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    title TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    metadata JSONB,  -- å­˜å‚¨æ¨¡å‹é…ç½®ã€å·¥å…·è®¾ç½®ç­‰
    
    INDEX idx_user_created (user_id, created_at DESC)
);

-- ===== æ¶ˆæ¯è¡¨ï¼ˆåˆ†åŒºè¡¨ï¼‰=====
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES conversations(id),
    role TEXT NOT NULL,  -- 'user', 'assistant', 'system', 'tool'
    content TEXT,
    tool_calls JSONB,  -- å·¥å…·è°ƒç”¨è®°å½•
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    INDEX idx_conversation_created (conversation_id, created_at)
) PARTITION BY RANGE (created_at);

-- æŒ‰æœˆåˆ†åŒºï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
CREATE TABLE messages_2024_01 PARTITION OF messages
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- ===== å·¥å…·è°ƒç”¨æ—¥å¿—è¡¨ =====
CREATE TABLE tool_executions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    message_id UUID REFERENCES messages(id),
    tool_name TEXT NOT NULL,
    input JSONB,
    output JSONB,
    duration_ms INTEGER,
    status TEXT,  -- 'success', 'error'
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    INDEX idx_tool_created (tool_name, created_at DESC)
);

-- ===== ç”¨æˆ·é…é¢è¡¨ =====
CREATE TABLE user_quotas (
    user_id UUID PRIMARY KEY REFERENCES users(id),
    tokens_used BIGINT DEFAULT 0,
    tokens_limit BIGINT,
    reset_at TIMESTAMPTZ,
    
    INDEX idx_reset (reset_at)
);
```

### 3.4 ç¼“å­˜ç­–ç•¥

```python
# ===== Redis ç¼“å­˜å±‚ =====
import redis
from functools import wraps

redis_client = redis.Redis(host='redis', port=6379, decode_responses=True)

def cache_llm_response(ttl=3600):
    """ç¼“å­˜ç›¸åŒçš„ LLM è¯·æ±‚ï¼ˆèŠ‚çœæˆæœ¬ï¼‰"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"llm:{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # è°ƒç”¨ LLM
            result = await func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            redis_client.setex(cache_key, ttl, json.dumps(result))
            
            return result
        return wrapper
    return decorator

@cache_llm_response(ttl=7200)
async def call_llm(prompt: str, model: str):
    return await client.chat.completions.create(...)


# ===== ä¼šè¯çŠ¶æ€ç¼“å­˜ =====
class ConversationCache:
    """å°†æ´»è·ƒä¼šè¯ç¼“å­˜åˆ° Redisï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢"""
    
    @staticmethod
    def get_conversation(conv_id: str):
        key = f"conv:{conv_id}"
        data = redis_client.get(key)
        
        if data:
            return json.loads(data)
        
        # ä»æ•°æ®åº“åŠ è½½
        conv = db.query(Conversation).filter_by(id=conv_id).first()
        
        # ç¼“å­˜ 30 åˆ†é’Ÿ
        redis_client.setex(key, 1800, json.dumps(conv.to_dict()))
        
        return conv
    
    @staticmethod
    def invalidate(conv_id: str):
        redis_client.delete(f"conv:{conv_id}")
```

---

## 4. å®¹å™¨ç¼–æ’ä¸éƒ¨ç½²

### 4.1 Kubernetes æ¶æ„

```yaml
# ===== deployment.yaml =====
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chat-api
spec:
  replicas: 10  # æ°´å¹³æ‰©å±•
  selector:
    matchLabels:
      app: chat-api
  template:
    metadata:
      labels:
        app: chat-api
    spec:
      containers:
      - name: api
        image: chat-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# ===== service.yaml =====
apiVersion: v1
kind: Service
metadata:
  name: chat-api-service
spec:
  type: LoadBalancer
  selector:
    app: chat-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000

---
# ===== hpa.yaml (è‡ªåŠ¨æ‰©ç¼©å®¹) =====
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: chat-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: chat-api
  minReplicas: 5
  maxReplicas: 100
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 4.2 Docker Composeï¼ˆæ”¹è¿›ç‰ˆï¼‰

```yaml
# ===== docker-compose.prod.yaml =====
version: '3.8'

services:
  # API æœåŠ¡ï¼ˆå¯æ‰©å±•å¤šä¸ªå®ä¾‹ï¼‰
  api:
    build: .
    image: chat-api:latest
    deploy:
      replicas: 3  # è¿è¡Œ 3 ä¸ªå®ä¾‹
      resources:
        limits:
          cpus: '2'
          memory: 2G
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/chatdb
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/1
    depends_on:
      - postgres
      - redis
    ports:
      - "8000-8002:8000"  # æ˜ å°„åˆ°ä¸åŒç«¯å£
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Workerï¼ˆå¤„ç†å¼‚æ­¥ä»»åŠ¡ï¼‰
  celery-worker:
    image: chat-api:latest
    command: celery -A tasks worker --loglevel=info --concurrency=4
    deploy:
      replicas: 5  # 5 ä¸ª worker
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/chatdb
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/1
    depends_on:
      - postgres
      - redis

  # Celery Beatï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
  celery-beat:
    image: chat-api:latest
    command: celery -A tasks beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
    depends_on:
      - redis

  # PostgreSQLï¼ˆä¸»æ•°æ®åº“ï¼‰
  postgres:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=chatdb
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redisï¼ˆç¼“å­˜ + æ¶ˆæ¯é˜Ÿåˆ—ï¼‰
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes

  # Nginxï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api

  # Flowerï¼ˆCelery ç›‘æ§ï¼‰
  flower:
    image: mher/flower
    command: celery --broker=redis://redis:6379/1 flower --port=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis

volumes:
  postgres_data:
  redis_data:
```

---

## 5. ç›‘æ§ä¸å¯è§‚æµ‹æ€§

```python
# ===== é›†æˆ Prometheus æŒ‡æ ‡ =====
from prometheus_client import Counter, Histogram, Gauge
from prometheus_fastapi_instrumentator import Instrumentator

# è‡ªå®šä¹‰æŒ‡æ ‡
llm_requests_total = Counter(
    'llm_requests_total',
    'Total LLM API requests',
    ['model', 'status']
)

llm_latency = Histogram(
    'llm_latency_seconds',
    'LLM API latency',
    ['model']
)

active_conversations = Gauge(
    'active_conversations',
    'Number of active conversations'
)

# åœ¨ FastAPI ä¸­ä½¿ç”¨
@app.post("/chat")
async def chat(request: ChatRequest):
    start_time = time.time()
    
    try:
        response = await call_llm(request.message, request.model)
        
        llm_requests_total.labels(
            model=request.model,
            status='success'
        ).inc()
        
        return response
    
    except Exception as e:
        llm_requests_total.labels(
            model=request.model,
            status='error'
        ).inc()
        raise
    
    finally:
        duration = time.time() - start_time
        llm_latency.labels(model=request.model).observe(duration)

# å¯åŠ¨æ—¶æ³¨å†Œ
Instrumentator().instrument(app).expose(app)
```

---

## 6. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### 6.1 LLM è°ƒç”¨ä¼˜åŒ–

```python
# ===== æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹ =====
class ModelRouter:
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æœ€ç»æµçš„æ¨¡å‹"""
    
    MODELS = {
        'simple': 'openai:gpt-3.5-turbo',      # $0.0015/1K tokens
        'medium': 'openai:gpt-4o-mini',        # $0.15/1M tokens
        'complex': 'anthropic:claude-3-5-sonnet',  # $3/1M tokens
    }
    
    @staticmethod
    def classify_complexity(prompt: str) -> str:
        """åˆ†ç±»ä»»åŠ¡å¤æ‚åº¦"""
        if len(prompt) < 100 and '?' in prompt:
            return 'simple'
        elif any(kw in prompt.lower() for kw in ['analyze', 'research', 'compare']):
            return 'complex'
        else:
            return 'medium'
    
    @classmethod
    def route(cls, prompt: str) -> str:
        complexity = cls.classify_complexity(prompt)
        return cls.MODELS[complexity]

# ä½¿ç”¨
model = ModelRouter.route(user_prompt)
response = await client.chat.completions.create(model=model, ...)
```

### 6.2 æ‰¹å¤„ç†ä¼˜åŒ–

```python
# ===== æ‰¹é‡å¤„ç†å·¥å…·è°ƒç”¨ =====
async def batch_tool_calls(tool_calls: List[ToolCall]):
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨ï¼Œå‡å°‘å»¶è¿Ÿ"""
    tasks = [
        execute_tool(tc.name, tc.arguments)
        for tc in tool_calls
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return results
```

---

## 7. å®‰å…¨æ€§æªæ–½

```python
# ===== é™æµ =====
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/chat")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿ 10 æ¬¡
async def chat(request: Request, chat_req: ChatRequest):
    ...

# ===== å†…å®¹è¿‡æ»¤ =====
from openai import OpenAI

moderation_client = OpenAI()

async def moderate_content(text: str) -> bool:
    """æ£€æŸ¥å†…å®¹æ˜¯å¦è¿è§„"""
    response = moderation_client.moderations.create(input=text)
    
    return not response.results[0].flagged

@app.post("/chat")
async def chat(request: ChatRequest):
    if not await moderate_content(request.message):
        raise HTTPException(status_code=400, detail="Content violates policy")
    
    ...

# ===== Prompt æ³¨å…¥é˜²æŠ¤ =====
def sanitize_prompt(user_input: str) -> str:
    """é˜²æ­¢ prompt æ³¨å…¥æ”»å‡»"""
    # ç§»é™¤ç‰¹æ®ŠæŒ‡ä»¤
    dangerous_patterns = [
        r'ignore previous instructions',
        r'system:',
        r'<\|im_start\|>',
    ]
    
    for pattern in dangerous_patterns:
        user_input = re.sub(pattern, '', user_input, flags=re.IGNORECASE)
    
    return user_input
```

---

## æ€»ç»“ï¼šå½“å‰é¡¹ç›® vs ç”Ÿäº§ç¯å¢ƒ

| ç»´åº¦ | å½“å‰é¡¹ç›® | ç”Ÿäº§ç¯å¢ƒ (ChatGPT/Claude çº§åˆ«) |
|------|---------|-------------------------------|
| **å¹¶å‘å¤„ç†** | threading (å•æœº) | Celery + Kubernetes (åˆ†å¸ƒå¼) |
| **å®æ—¶é€šä¿¡** | è½®è¯¢ | WebSocket / SSE |
| **æ•°æ®åº“** | å•å®¹å™¨ Postgres | ä¸»ä»å¤åˆ¶ + è¯»å†™åˆ†ç¦» + åˆ†ç‰‡ |
| **ç¼“å­˜** | æ—  | Redis å¤šå±‚ç¼“å­˜ |
| **è´Ÿè½½å‡è¡¡** | æ—  | Nginx/ALB + è‡ªåŠ¨æ‰©ç¼©å®¹ |
| **ç›‘æ§** | æ—  | Prometheus + Grafana + ELK |
| **å®¹é”™** | æ—  | å¤šå¯ç”¨åŒº + è‡ªåŠ¨æ•…éšœè½¬ç§» |
| **æˆæœ¬** | ä¸è€ƒè™‘ | æ™ºèƒ½è·¯ç”± + ç¼“å­˜ + æ‰¹å¤„ç† |

