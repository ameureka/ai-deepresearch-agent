"""
å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰å®Œæ•´å®ç°ç¤ºä¾‹
å±•ç¤º OpenAIã€Anthropicã€aisuite ä¸‰ç§æ–¹å¼
"""

import json
import requests
from typing import List, Dict, Any

# ============================================================
# Part 1: å·¥å…·å®šä¹‰çš„æ ‡å‡†æ ¼å¼
# ============================================================

# OpenAI æ ¼å¼ï¼ˆJSON Schemaï¼‰
openai_tool_definition = {
    "type": "function",
    "function": {
        "name": "tavily_search_tool",
        "description": "Search the web using Tavily API for current information",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The search query string"
                },
                "max_results": {
                    "type": "integer",
                    "description": "Maximum number of results to return",
                    "default": 5
                },
                "include_images": {
                    "type": "boolean",
                    "description": "Whether to include image results",
                    "default": False
                }
            },
            "required": ["query"]
        }
    }
}

# Anthropic æ ¼å¼ï¼ˆç•¥æœ‰ä¸åŒï¼‰
anthropic_tool_definition = {
    "name": "tavily_search_tool",
    "description": "Search the web using Tavily API for current information",
    "input_schema": {  # æ³¨æ„ï¼šè¿™é‡Œæ˜¯ input_schema è€Œä¸æ˜¯ parameters
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "The search query string"
            },
            "max_results": {
                "type": "integer",
                "description": "Maximum number of results to return",
                "default": 5
            },
            "include_images": {
                "type": "boolean",
                "description": "Whether to include image results",
                "default": False
            }
        },
        "required": ["query"]
    }
}


# ============================================================
# Part 2: å®é™…å·¥å…·å‡½æ•°å®ç°
# ============================================================

def tavily_search_tool(query: str, max_results: int = 5, include_images: bool = False) -> List[Dict]:
    """
    å®é™…æ‰§è¡Œæœç´¢çš„å‡½æ•°
    è¿™æ˜¯çœŸæ­£è¢«è°ƒç”¨çš„ Python å‡½æ•°
    """
    import os
    from tavily import TavilyClient
    
    api_key = os.getenv("TAVILY_API_KEY")
    client = TavilyClient(api_key)
    
    try:
        response = client.search(
            query=query,
            max_results=max_results,
            include_images=include_images
        )
        
        results = []
        for r in response.get("results", []):
            results.append({
                "title": r.get("title", ""),
                "content": r.get("content", ""),
                "url": r.get("url", "")
            })
        
        return results
    
    except Exception as e:
        return [{"error": str(e)}]


def arxiv_search_tool(query: str, max_results: int = 3) -> List[Dict]:
    """arXiv æœç´¢å·¥å…·"""
    # å®ç°ç»†èŠ‚è§ src/research_tools.py
    pass


def wikipedia_search_tool(query: str, sentences: int = 5) -> List[Dict]:
    """Wikipedia æœç´¢å·¥å…·"""
    # å®ç°ç»†èŠ‚è§ src/research_tools.py
    pass


# å·¥å…·æ˜ å°„è¡¨ï¼ˆå…³é”®ï¼ï¼‰
TOOL_MAPPING = {
    "tavily_search_tool": tavily_search_tool,
    "arxiv_search_tool": arxiv_search_tool,
    "wikipedia_search_tool": wikipedia_search_tool,
}


# ============================================================
# Part 3: OpenAI åŸç”Ÿå®ç°ï¼ˆæ‰‹åŠ¨å¤„ç†ï¼‰
# ============================================================

from openai import OpenAI

def openai_manual_tool_calling():
    """
    OpenAI æ‰‹åŠ¨å®ç°å·¥å…·è°ƒç”¨
    å±•ç¤ºåº•å±‚å·¥ä½œåŸç†
    """
    client = OpenAI()
    
    # 1. å®šä¹‰å·¥å…·
    tools = [
        openai_tool_definition,
        # å¯ä»¥æ·»åŠ æ›´å¤šå·¥å…·...
    ]
    
    # 2. åˆå§‹æ¶ˆæ¯
    messages = [
        {"role": "user", "content": "æœç´¢å…³äº Large Language Models çš„æœ€æ–°ä¿¡æ¯"}
    ]
    
    print("=" * 60)
    print("ç¬¬ä¸€è½®ï¼šLLM å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·")
    print("=" * 60)
    
    # 3. ç¬¬ä¸€æ¬¡è°ƒç”¨ LLM
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        tools=tools,
        tool_choice="auto"  # è®©æ¨¡å‹è‡ªå·±å†³å®š
    )
    
    response_message = response.choices[0].message
    
    # 4. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if response_message.tool_calls:
        print(f"âœ… LLM å†³å®šè°ƒç”¨ {len(response_message.tool_calls)} ä¸ªå·¥å…·\n")
        
        # å°† LLM çš„å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        messages.append(response_message)
        
        # 5. æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
        for tool_call in response_message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            
            print(f"ğŸ“ è°ƒç”¨å·¥å…·: {function_name}")
            print(f"ğŸ“ å‚æ•°: {json.dumps(function_args, indent=2, ensure_ascii=False)}")
            
            # 6. æ‰§è¡Œå®é™…çš„ Python å‡½æ•°
            function_to_call = TOOL_MAPPING[function_name]
            function_response = function_to_call(**function_args)
            
            print(f"âœ… å·¥å…·è¿”å›: {len(function_response)} æ¡ç»“æœ\n")
            
            # 7. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            messages.append({
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": function_name,
                "content": json.dumps(function_response, ensure_ascii=False)
            })
        
        print("=" * 60)
        print("ç¬¬äºŒè½®ï¼šLLM åŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤")
        print("=" * 60)
        
        # 8. ç¬¬äºŒæ¬¡è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·ç»“æœï¼‰
        second_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        
        final_answer = second_response.choices[0].message.content
        print(f"ğŸ¯ æœ€ç»ˆå›å¤:\n{final_answer}\n")
        
        return final_answer
    
    else:
        print("âŒ LLM å†³å®šä¸è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›å¤")
        return response_message.content


# ============================================================
# Part 4: Anthropic Claude åŸç”Ÿå®ç°
# ============================================================

from anthropic import Anthropic

def anthropic_manual_tool_calling():
    """
    Anthropic Claude æ‰‹åŠ¨å®ç°å·¥å…·è°ƒç”¨
    æ ¼å¼ä¸ OpenAI ç•¥æœ‰ä¸åŒ
    """
    client = Anthropic()
    
    # 1. å®šä¹‰å·¥å…·ï¼ˆæ³¨æ„æ ¼å¼å·®å¼‚ï¼‰
    tools = [
        anthropic_tool_definition,
        # å¯ä»¥æ·»åŠ æ›´å¤šå·¥å…·...
    ]
    
    # 2. åˆå§‹æ¶ˆæ¯
    messages = [
        {"role": "user", "content": "æœç´¢å…³äº Large Language Models çš„æœ€æ–°ä¿¡æ¯"}
    ]
    
    print("=" * 60)
    print("Claude å·¥å…·è°ƒç”¨æµç¨‹")
    print("=" * 60)
    
    # 3. å¤šè½®å¯¹è¯å¾ªç¯ï¼ˆClaude éœ€è¦æ‰‹åŠ¨å®ç°ï¼‰
    max_turns = 5
    
    for turn in range(max_turns):
        print(f"\n--- ç¬¬ {turn + 1} è½® ---")
        
        # 4. è°ƒç”¨ Claude
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4096,
            tools=tools,
            messages=messages
        )
        
        print(f"Stop reason: {response.stop_reason}")
        
        # 5. æ£€æŸ¥åœæ­¢åŸå› 
        if response.stop_reason == "tool_use":
            # å°† Claude çš„å“åº”æ·»åŠ åˆ°å†å²
            messages.append({
                "role": "assistant",
                "content": response.content
            })
            
            # 6. å¤„ç†å·¥å…·è°ƒç”¨
            tool_results = []
            
            for content_block in response.content:
                if content_block.type == "tool_use":
                    tool_name = content_block.name
                    tool_input = content_block.input
                    
                    print(f"ğŸ“ è°ƒç”¨å·¥å…·: {tool_name}")
                    print(f"ğŸ“ å‚æ•°: {json.dumps(tool_input, indent=2, ensure_ascii=False)}")
                    
                    # 7. æ‰§è¡Œå®é™…å‡½æ•°
                    function_to_call = TOOL_MAPPING[tool_name]
                    function_response = function_to_call(**tool_input)
                    
                    print(f"âœ… å·¥å…·è¿”å›: {len(function_response)} æ¡ç»“æœ")
                    
                    # 8. æ„é€ å·¥å…·ç»“æœï¼ˆæ³¨æ„æ ¼å¼ï¼‰
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": content_block.id,
                        "content": json.dumps(function_response, ensure_ascii=False)
                    })
            
            # 9. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            messages.append({
                "role": "user",
                "content": tool_results
            })
        
        elif response.stop_reason == "end_turn":
            # 10. è·å–æœ€ç»ˆæ–‡æœ¬å›å¤
            final_text = ""
            for content_block in response.content:
                if hasattr(content_block, "text"):
                    final_text += content_block.text
            
            print(f"\nğŸ¯ æœ€ç»ˆå›å¤:\n{final_text}")
            return final_text
        
        else:
            print(f"âš ï¸ æœªé¢„æœŸçš„åœæ­¢åŸå› : {response.stop_reason}")
            break
    
    return "è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶"


# ============================================================
# Part 5: aisuite ç»Ÿä¸€å®ç°ï¼ˆæ¨èï¼‰
# ============================================================

from aisuite import Client

def aisuite_unified_tool_calling(model="openai:gpt-4o-mini"):
    """
    aisuite ç»Ÿä¸€æ¥å£
    è‡ªåŠ¨å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
    """
    client = Client()
    
    # 1. å®šä¹‰å·¥å…·ï¼ˆä½¿ç”¨ OpenAI æ ¼å¼ï¼‰
    tools = [
        openai_tool_definition,
        # aisuite ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºç›®æ ‡æ¨¡å‹çš„æ ¼å¼
    ]
    
    print("=" * 60)
    print(f"aisuite ç»Ÿä¸€æ¥å£ (æ¨¡å‹: {model})")
    print("=" * 60)
    
    # 2. ä¸€æ¬¡è°ƒç”¨ï¼Œè‡ªåŠ¨å¤„ç†å¤šè½®
    response = client.chat.completions.create(
        model=model,  # å¯ä»¥æ˜¯ "openai:gpt-4o-mini" æˆ– "anthropic:claude-3-5-sonnet"
        messages=[
            {"role": "user", "content": "æœç´¢å…³äº Large Language Models çš„æœ€æ–°ä¿¡æ¯"}
        ],
        tools=tools,
        tool_choice="auto",
        max_turns=5,  # ğŸ”¥ å…³é”®å‚æ•°ï¼šè‡ªåŠ¨å¤„ç†æœ€å¤š 5 è½®å·¥å…·è°ƒç”¨
        temperature=0
    )
    
    # 3. ç›´æ¥è·å–æœ€ç»ˆç»“æœ
    final_answer = response.choices[0].message.content
    
    print(f"ğŸ¯ æœ€ç»ˆå›å¤:\n{final_answer}\n")
    
    # 4. æŸ¥çœ‹å·¥å…·è°ƒç”¨å†å²ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if hasattr(response.choices[0].message, 'intermediate_messages'):
        print("=" * 60)
        print("å·¥å…·è°ƒç”¨å†å²:")
        print("=" * 60)
        
        for msg in response.choices[0].message.intermediate_messages:
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    print(f"ğŸ“ {tc.function.name}({tc.function.arguments})")
    
    return final_answer


# ============================================================
# Part 6: å·¥å…·å‚æ•°çš„è¯¦ç»†è§£æ
# ============================================================

def analyze_tool_parameters():
    """
    åˆ†æå·¥å…·å®šä¹‰ä¸­çš„å‚æ•°ç»“æ„
    """
    print("=" * 60)
    print("å·¥å…·å‚æ•°ç»“æ„è¯¦è§£")
    print("=" * 60)
    
    tool_def = {
        "type": "function",  # å›ºå®šå€¼
        "function": {
            # ===== ä¸€çº§å‚æ•° =====
            "name": "tool_name",  # å·¥å…·åç§°ï¼ˆå¿…éœ€ï¼‰
            "description": "å·¥å…·çš„è¯¦ç»†æè¿°ï¼Œå¸®åŠ© LLM ç†è§£ä½•æ—¶ä½¿ç”¨",  # æè¿°ï¼ˆå¿…éœ€ï¼‰
            
            # ===== parameters å¯¹è±¡ï¼ˆæ ¸å¿ƒï¼‰=====
            "parameters": {
                "type": "object",  # å›ºå®šä¸º object
                
                # ===== propertiesï¼šå®šä¹‰æ¯ä¸ªå‚æ•° =====
                "properties": {
                    "param1": {
                        "type": "string",  # ç±»å‹ï¼šstring, integer, boolean, array, object
                        "description": "å‚æ•°1çš„æè¿°",
                        "enum": ["option1", "option2"],  # å¯é€‰ï¼šæšä¸¾å€¼
                    },
                    "param2": {
                        "type": "integer",
                        "description": "å‚æ•°2çš„æè¿°",
                        "minimum": 1,  # å¯é€‰ï¼šæœ€å°å€¼
                        "maximum": 100,  # å¯é€‰ï¼šæœ€å¤§å€¼
                        "default": 10  # å¯é€‰ï¼šé»˜è®¤å€¼
                    },
                    "param3": {
                        "type": "array",
                        "description": "å‚æ•°3æ˜¯æ•°ç»„",
                        "items": {
                            "type": "string"  # æ•°ç»„å…ƒç´ ç±»å‹
                        }
                    },
                    "param4": {
                        "type": "object",
                        "description": "å‚æ•°4æ˜¯åµŒå¥—å¯¹è±¡",
                        "properties": {
                            "nested_field": {
                                "type": "string"
                            }
                        }
                    }
                },
                
                # ===== requiredï¼šå¿…éœ€å‚æ•°åˆ—è¡¨ =====
                "required": ["param1", "param2"]
            }
        }
    }
    
    print(json.dumps(tool_def, indent=2, ensure_ascii=False))
    
    print("\n" + "=" * 60)
    print("å‚æ•°ç±»å‹è¯´æ˜:")
    print("=" * 60)
    print("""
    1. string   - å­—ç¬¦ä¸²
    2. integer  - æ•´æ•°
    3. number   - æµ®ç‚¹æ•°
    4. boolean  - å¸ƒå°”å€¼
    5. array    - æ•°ç»„ï¼ˆéœ€è¦å®šä¹‰ itemsï¼‰
    6. object   - å¯¹è±¡ï¼ˆéœ€è¦å®šä¹‰ propertiesï¼‰
    7. null     - ç©ºå€¼
    
    å¸¸ç”¨çº¦æŸ:
    - enum: é™åˆ¶å¯é€‰å€¼
    - minimum/maximum: æ•°å€¼èŒƒå›´
    - minLength/maxLength: å­—ç¬¦ä¸²é•¿åº¦
    - pattern: æ­£åˆ™è¡¨è¾¾å¼
    - default: é»˜è®¤å€¼
    """)


# ============================================================
# Part 7: å®é™…é¡¹ç›®ä¸­çš„å·¥å…·å®šä¹‰ç¤ºä¾‹
# ============================================================

# ä»å½“å‰é¡¹ç›®æå–çš„å®é™…å·¥å…·å®šä¹‰
ACTUAL_TOOLS = [
    # Tavily æœç´¢
    {
        "type": "function",
        "function": {
            "name": "tavily_search_tool",
            "description": "Performs a general-purpose web search using the Tavily API.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search keywords for retrieving information from the web.",
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum number of results to return.",
                        "default": 5,
                    },
                    "include_images": {
                        "type": "boolean",
                        "description": "Whether to include image results.",
                        "default": False,
                    },
                },
                "required": ["query"],
            },
        },
    },
    
    # arXiv æœç´¢
    {
        "type": "function",
        "function": {
            "name": "arxiv_search_tool",
            "description": "Searches arXiv and (internally) fetches PDFs to memory and extracts text.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search keywords."
                    },
                    "max_results": {
                        "type": "integer",
                        "default": 3
                    },
                },
                "required": ["query"],
            },
        },
    },
    
    # Wikipedia æœç´¢
    {
        "type": "function",
        "function": {
            "name": "wikipedia_search_tool",
            "description": "Searches for a Wikipedia article summary by query string.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search keywords for the Wikipedia article.",
                    },
                    "sentences": {
                        "type": "integer",
                        "description": "Number of sentences in the summary.",
                        "default": 5,
                    },
                },
                "required": ["query"],
            },
        },
    },
]


# ============================================================
# æµ‹è¯•è¿è¡Œ
# ============================================================

if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("å·¥å…·è°ƒç”¨å®ç°å¯¹æ¯”")
    print("=" * 60)
    
    # 1. åˆ†æå‚æ•°ç»“æ„
    analyze_tool_parameters()
    
    # 2. OpenAI æ‰‹åŠ¨å®ç°
    # openai_manual_tool_calling()
    
    # 3. Anthropic æ‰‹åŠ¨å®ç°
    # anthropic_manual_tool_calling()
    
    # 4. aisuite ç»Ÿä¸€å®ç°ï¼ˆæ¨èï¼‰
    # aisuite_unified_tool_calling("openai:gpt-4o-mini")
    # aisuite_unified_tool_calling("anthropic:claude-3-5-sonnet-20241022")
