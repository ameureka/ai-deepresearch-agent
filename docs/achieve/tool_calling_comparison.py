"""
å·¥å…·è°ƒç”¨å®ç°å¯¹æ¯”ï¼šOpenAI vs Anthropic vs aisuite
å®é™…å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹
"""

import json
import os
from typing import List, Dict

# ============================================================
# å®é™…å·¥å…·å‡½æ•°ï¼ˆæ‰€æœ‰å®ç°å…±ç”¨ï¼‰
# ============================================================

def mock_search_tool(query: str, max_results: int = 5) -> List[Dict]:
    """æ¨¡æ‹Ÿæœç´¢å·¥å…·"""
    return [
        {"title": f"Result {i+1} for '{query}'", "url": f"https://example.com/{i}"}
        for i in range(max_results)
    ]


# ============================================================
# æ–¹æ¡ˆ 1: OpenAI åŸç”Ÿå®ç°ï¼ˆæ‰‹åŠ¨å¤šè½®ï¼‰
# ============================================================

def openai_native_implementation():
    """
    OpenAI åŸç”Ÿ SDK å®ç°
    éœ€è¦æ‰‹åŠ¨å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
    """
    from openai import OpenAI
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # å·¥å…·å®šä¹‰ï¼ˆOpenAI æ ¼å¼ï¼‰
    tools = [
        {
            "type": "function",
            "function": {
                "name": "search_tool",
                "description": "æœç´¢ç½‘ç»œä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢å…³é”®è¯"
                        },
                        "max_results": {
                            "type": "integer",
                            "description": "æœ€å¤§ç»“æœæ•°",
                            "default": 5
                        }
                    },
                    "required": ["query"]
                }
            }
        }
    ]
    
    messages = [
        {"role": "user", "content": "æœç´¢ GPT-4 çš„ä¿¡æ¯"}
    ]
    
    print("=" * 80)
    print("OpenAI åŸç”Ÿå®ç°")
    print("=" * 80)
    
    # æ‰‹åŠ¨å®ç°å¤šè½®å¾ªç¯
    max_iterations = 5
    
    for iteration in range(max_iterations):
        print(f"\n--- ç¬¬ {iteration + 1} è½® ---")
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if response_message.tool_calls:
            print(f"âœ… æ£€æµ‹åˆ° {len(response_message.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            
            # æ·»åŠ  assistant æ¶ˆæ¯
            messages.append(response_message)
            
            # æ‰§è¡Œæ¯ä¸ªå·¥å…·
            for tool_call in response_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                print(f"  ğŸ“ {function_name}({json.dumps(function_args, ensure_ascii=False)})")
                
                # æ‰§è¡Œå®é™…å‡½æ•°
                if function_name == "search_tool":
                    result = mock_search_tool(**function_args)
                else:
                    result = {"error": "Unknown function"}
                
                print(f"  âœ… è¿”å› {len(result)} æ¡ç»“æœ")
                
                # æ·»åŠ å·¥å…·ç»“æœ
                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": json.dumps(result, ensure_ascii=False)
                })
        
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè·å–æœ€ç»ˆå›å¤
            print(f"âœ… ç”Ÿæˆæœ€ç»ˆå›å¤")
            final_answer = response_message.content
            print(f"\næœ€ç»ˆå›å¤:\n{final_answer}")
            return final_answer
    
    print("âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°")
    return None


# ============================================================
# æ–¹æ¡ˆ 2: Anthropic åŸç”Ÿå®ç°ï¼ˆæ‰‹åŠ¨å¤šè½®ï¼‰
# ============================================================

def anthropic_native_implementation():
    """
    Anthropic Claude åŸç”Ÿ SDK å®ç°
    æ ¼å¼ä¸ OpenAI ä¸åŒï¼Œä¹Ÿéœ€è¦æ‰‹åŠ¨å¤„ç†å¤šè½®
    """
    from anthropic import Anthropic
    
    client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
    
    # å·¥å…·å®šä¹‰ï¼ˆAnthropic æ ¼å¼ - æ³¨æ„å·®å¼‚ï¼‰
    tools = [
        {
            "name": "search_tool",  # æ²¡æœ‰ type å­—æ®µ
            "description": "æœç´¢ç½‘ç»œä¿¡æ¯",
            "input_schema": {  # ä¸æ˜¯ parametersï¼Œæ˜¯ input_schema
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯"
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "æœ€å¤§ç»“æœæ•°",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        }
    ]
    
    messages = [
        {"role": "user", "content": "æœç´¢ GPT-4 çš„ä¿¡æ¯"}
    ]
    
    print("=" * 80)
    print("Anthropic åŸç”Ÿå®ç°")
    print("=" * 80)
    
    # æ‰‹åŠ¨å®ç°å¤šè½®å¾ªç¯
    max_iterations = 5
    
    for iteration in range(max_iterations):
        print(f"\n--- ç¬¬ {iteration + 1} è½® ---")
        
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4096,
            tools=tools,
            messages=messages
        )
        
        print(f"Stop reason: {response.stop_reason}")
        
        # æ£€æŸ¥åœæ­¢åŸå› 
        if response.stop_reason == "tool_use":
            print(f"âœ… æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
            
            # æ·»åŠ  assistant æ¶ˆæ¯
            messages.append({
                "role": "assistant",
                "content": response.content
            })
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            tool_results = []
            
            for content_block in response.content:
                if content_block.type == "tool_use":
                    tool_name = content_block.name
                    tool_input = content_block.input
                    
                    print(f"  ğŸ“ {tool_name}({json.dumps(tool_input, ensure_ascii=False)})")
                    
                    # æ‰§è¡Œå®é™…å‡½æ•°
                    if tool_name == "search_tool":
                        result = mock_search_tool(**tool_input)
                    else:
                        result = {"error": "Unknown function"}
                    
                    print(f"  âœ… è¿”å› {len(result)} æ¡ç»“æœ")
                    
                    # æ„é€ å·¥å…·ç»“æœï¼ˆæ³¨æ„æ ¼å¼ï¼‰
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": content_block.id,
                        "content": json.dumps(result, ensure_ascii=False)
                    })
            
            # æ·»åŠ å·¥å…·ç»“æœ
            messages.append({
                "role": "user",
                "content": tool_results
            })
        
        elif response.stop_reason == "end_turn":
            # è·å–æœ€ç»ˆæ–‡æœ¬
            print(f"âœ… ç”Ÿæˆæœ€ç»ˆå›å¤")
            final_text = ""
            for content_block in response.content:
                if hasattr(content_block, "text"):
                    final_text += content_block.text
            
            print(f"\næœ€ç»ˆå›å¤:\n{final_text}")
            return final_text
        
        else:
            print(f"âš ï¸ æœªé¢„æœŸçš„åœæ­¢åŸå› : {response.stop_reason}")
            break
    
    print("âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°")
    return None


# ============================================================
# æ–¹æ¡ˆ 3: aisuite ç»Ÿä¸€å®ç°ï¼ˆè‡ªåŠ¨å¤šè½®ï¼‰
# ============================================================

def aisuite_unified_implementation(model="openai:gpt-4o-mini"):
    """
    aisuite ç»Ÿä¸€æ¥å£
    è‡ªåŠ¨å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨ï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹
    """
    from aisuite import Client
    
    client = Client()
    
    # å·¥å…·å®šä¹‰ï¼ˆä½¿ç”¨ OpenAI æ ¼å¼ï¼Œaisuite ä¼šè‡ªåŠ¨è½¬æ¢ï¼‰
    tools = [
        {
            "type": "function",
            "function": {
                "name": "search_tool",
                "description": "æœç´¢ç½‘ç»œä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢å…³é”®è¯"
                        },
                        "max_results": {
                            "type": "integer",
                            "description": "æœ€å¤§ç»“æœæ•°",
                            "default": 5
                        }
                    },
                    "required": ["query"]
                }
            }
        }
    ]
    
    print("=" * 80)
    print(f"aisuite ç»Ÿä¸€å®ç° (æ¨¡å‹: {model})")
    print("=" * 80)
    
    # ğŸ”¥ ä¸€æ¬¡è°ƒç”¨ï¼Œè‡ªåŠ¨å¤„ç†å¤šè½®
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "user", "content": "æœç´¢ GPT-4 çš„ä¿¡æ¯"}
        ],
        tools=tools,
        tool_choice="auto",
        max_turns=5,  # è‡ªåŠ¨å¤„ç†æœ€å¤š 5 è½®
        temperature=0
    )
    
    # ç›´æ¥è·å–æœ€ç»ˆç»“æœ
    final_answer = response.choices[0].message.content
    
    print(f"âœ… å®Œæˆï¼ˆè‡ªåŠ¨å¤„ç†äº†å¤šè½®å·¥å…·è°ƒç”¨ï¼‰")
    print(f"\næœ€ç»ˆå›å¤:\n{final_answer}")
    
    # æŸ¥çœ‹å·¥å…·è°ƒç”¨å†å²
    if hasattr(response.choices[0].message, 'intermediate_messages'):
        print("\n" + "=" * 80)
        print("å·¥å…·è°ƒç”¨å†å²:")
        print("=" * 80)
        
        for i, msg in enumerate(response.choices[0].message.intermediate_messages, 1):
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    print(f"  {i}. {tc.function.name}({tc.function.arguments})")
    
    return final_answer


# ============================================================
# å¯¹æ¯”æ€»ç»“
# ============================================================

def print_comparison_summary():
    """
    æ‰“å°ä¸‰ç§å®ç°æ–¹å¼çš„å¯¹æ¯”
    """
    print("\n" + "=" * 80)
    print("ä¸‰ç§å®ç°æ–¹å¼å¯¹æ¯”")
    print("=" * 80)
    
    comparison = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ç‰¹æ€§        â”‚   OpenAI åŸç”Ÿ    â”‚  Anthropic åŸç”Ÿ  â”‚     aisuite      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¤šè½®å¤„ç†        â”‚ âŒ æ‰‹åŠ¨å¾ªç¯      â”‚ âŒ æ‰‹åŠ¨å¾ªç¯      â”‚ âœ… è‡ªåŠ¨å¤„ç†      â”‚
â”‚ ä»£ç å¤æ‚åº¦      â”‚ é«˜ï¼ˆ50+ è¡Œï¼‰     â”‚ é«˜ï¼ˆ60+ è¡Œï¼‰     â”‚ ä½ï¼ˆ10 è¡Œï¼‰      â”‚
â”‚ å·¥å…·å®šä¹‰æ ¼å¼    â”‚ parameters       â”‚ input_schema     â”‚ parameters       â”‚
â”‚ æ¨¡å‹åˆ‡æ¢        â”‚ âŒ éœ€è¦é‡å†™      â”‚ âŒ éœ€è¦é‡å†™      â”‚ âœ… æ”¹ä¸€ä¸ªå‚æ•°    â”‚
â”‚ é”™è¯¯å¤„ç†        â”‚ éœ€è¦è‡ªå·±å®ç°     â”‚ éœ€è¦è‡ªå·±å®ç°     â”‚ å†…ç½®å¤„ç†         â”‚
â”‚ è°ƒè¯•ä¿¡æ¯        â”‚ éœ€è¦è‡ªå·±è®°å½•     â”‚ éœ€è¦è‡ªå·±è®°å½•     â”‚ æä¾›å†å²è®°å½•     â”‚
â”‚ å­¦ä¹ æ›²çº¿        â”‚ ä¸­ç­‰             â”‚ ä¸­ç­‰             â”‚ ä½               â”‚
â”‚ çµæ´»æ€§          â”‚ é«˜               â”‚ é«˜               â”‚ ä¸­               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä»£ç è¡Œæ•°å¯¹æ¯”ï¼ˆå®ç°ç›¸åŒåŠŸèƒ½ï¼‰:
  - OpenAI åŸç”Ÿ:    ~50 è¡Œ
  - Anthropic åŸç”Ÿ: ~60 è¡Œ
  - aisuite:        ~10 è¡Œ

æ¨èä½¿ç”¨åœºæ™¯:
  - OpenAI åŸç”Ÿ:    éœ€è¦ç²¾ç»†æ§åˆ¶æ¯ä¸€æ­¥ï¼Œæˆ–ä½¿ç”¨ OpenAI ç‹¬æœ‰ç‰¹æ€§
  - Anthropic åŸç”Ÿ: éœ€è¦ Claude çš„ç‰¹å®šåŠŸèƒ½ï¼Œæˆ–ç²¾ç»†æ§åˆ¶
  - aisuite:        å¿«é€Ÿå¼€å‘ï¼Œéœ€è¦å¤šæ¨¡å‹æ”¯æŒï¼Œæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ âœ…
"""
    
    print(comparison)


# ============================================================
# å·¥å…·å®šä¹‰æ ¼å¼å¯¹æ¯”
# ============================================================

def print_format_comparison():
    """
    æ‰“å°å·¥å…·å®šä¹‰æ ¼å¼çš„è¯¦ç»†å¯¹æ¯”
    """
    print("\n" + "=" * 80)
    print("å·¥å…·å®šä¹‰æ ¼å¼å¯¹æ¯”")
    print("=" * 80)
    
    print("\nã€OpenAI æ ¼å¼ã€‘")
    print("-" * 80)
    openai_format = {
        "type": "function",  # â† éœ€è¦è¿™ä¸ªå­—æ®µ
        "function": {
            "name": "search_tool",
            "description": "æœç´¢å·¥å…·",
            "parameters": {  # â† å…³é”®å­—: parameters
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                },
                "required": ["query"]
            }
        }
    }
    print(json.dumps(openai_format, indent=2, ensure_ascii=False))
    
    print("\nã€Anthropic æ ¼å¼ã€‘")
    print("-" * 80)
    anthropic_format = {
        # æ²¡æœ‰ type å­—æ®µ
        "name": "search_tool",
        "description": "æœç´¢å·¥å…·",
        "input_schema": {  # â† å…³é”®å­—: input_schemaï¼ˆä¸æ˜¯ parametersï¼‰
            "type": "object",
            "properties": {
                "query": {"type": "string"}
            },
            "required": ["query"]
        }
    }
    print(json.dumps(anthropic_format, indent=2, ensure_ascii=False))
    
    print("\nã€aisuite æ ¼å¼ã€‘")
    print("-" * 80)
    print("ä½¿ç”¨ OpenAI æ ¼å¼ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸ºç›®æ ‡æ¨¡å‹çš„æ ¼å¼")
    print(json.dumps(openai_format, indent=2, ensure_ascii=False))


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("å·¥å…·è°ƒç”¨å®ç°å¯¹æ¯”æ¼”ç¤º")
    print("=" * 80)
    
    # 1. æ ¼å¼å¯¹æ¯”
    print_format_comparison()
    
    # 2. å®ç°å¯¹æ¯”æ€»ç»“
    print_comparison_summary()
    
    # 3. å®é™…è¿è¡Œç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œï¼‰
    # print("\n\n" + "=" * 80)
    # print("å®é™…è¿è¡Œç¤ºä¾‹")
    # print("=" * 80)
    
    # # OpenAI åŸç”Ÿ
    # openai_native_implementation()
    
    # # Anthropic åŸç”Ÿ
    # anthropic_native_implementation()
    
    # # aisuite ç»Ÿä¸€ï¼ˆOpenAIï¼‰
    # aisuite_unified_implementation("openai:gpt-4o-mini")
    
    # # aisuite ç»Ÿä¸€ï¼ˆClaudeï¼‰
    # aisuite_unified_implementation("anthropic:claude-3-5-sonnet-20241022")
