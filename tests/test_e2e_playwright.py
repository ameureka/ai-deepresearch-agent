"""
ç«¯åˆ°ç«¯æµ‹è¯• - ä½¿ç”¨ Playwright æµ‹è¯• Web ç•Œé¢

æµ‹è¯•èŒƒå›´:
1. é¦–é¡µåŠ è½½
2. æäº¤ç ”ç©¶ä»»åŠ¡
3. æŸ¥çœ‹ä»»åŠ¡è¿›åº¦
4. è·å–æœ€ç»ˆæŠ¥å‘Š
5. éªŒè¯ Phase 1.5 åŠŸèƒ½ï¼ˆæ—  max_tokens é”™è¯¯ï¼‰
"""

import pytest
import time
import requests
from playwright.sync_api import Page, expect


# æµ‹è¯•é…ç½®
BASE_URL = "http://localhost:8000"
TEST_PROMPT = "Artificial Intelligence in Healthcare"  # ç®€çŸ­ä¸»é¢˜ï¼Œå¿«é€Ÿæµ‹è¯•


def test_homepage_loads(page: Page):
    """æµ‹è¯• 1: é¦–é¡µæ˜¯å¦æ­£å¸¸åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯• 1: æ£€æŸ¥é¦–é¡µåŠ è½½...")

    page.goto(BASE_URL)

    # éªŒè¯é¡µé¢æ ‡é¢˜
    expect(page).to_have_title("Research Assistant")

    # éªŒè¯å…³é”®å…ƒç´ å­˜åœ¨
    expect(page.locator("h1")).to_contain_text("Reflective Research Agent")
    expect(page.locator("textarea[name='prompt']")).to_be_visible()
    expect(page.locator("button[type='submit']")).to_be_visible()

    print("âœ… é¦–é¡µåŠ è½½æˆåŠŸ")


def test_submit_research_task(page: Page):
    """æµ‹è¯• 2: æäº¤ç ”ç©¶ä»»åŠ¡"""
    print("\nğŸ§ª æµ‹è¯• 2: æäº¤ç ”ç©¶ä»»åŠ¡...")

    page.goto(BASE_URL)

    # å¡«å†™ç ”ç©¶ä¸»é¢˜
    page.locator("textarea[name='prompt']").fill(TEST_PROMPT)

    # é€‰æ‹©æ¨¡å‹ï¼ˆå¦‚æœæœ‰ä¸‹æ‹‰æ¡†ï¼‰
    model_selector = page.locator("select[name='model']")
    if model_selector.count() > 0:
        model_selector.select_option("deepseek:deepseek-chat")

    # ç‚¹å‡»æäº¤æŒ‰é’®
    page.locator("button[type='submit']").click()

    # ç­‰å¾…è·³è½¬åˆ°è¿›åº¦é¡µé¢æˆ–æ˜¾ç¤ºä»»åŠ¡ ID
    page.wait_for_timeout(2000)

    # éªŒè¯é¡µé¢å˜åŒ–ï¼ˆå¯èƒ½è·³è½¬åˆ° /task_progress/xxx æˆ–æ˜¾ç¤ºä»»åŠ¡ IDï¼‰
    current_url = page.url
    print(f"ğŸ“ å½“å‰ URL: {current_url}")

    assert BASE_URL in current_url
    print("âœ… ç ”ç©¶ä»»åŠ¡æäº¤æˆåŠŸ")


def test_api_submit_and_track():
    """æµ‹è¯• 3: é€šè¿‡ API æäº¤ä»»åŠ¡å¹¶è¿½è¸ªè¿›åº¦"""
    print("\nğŸ§ª æµ‹è¯• 3: API æäº¤ä»»åŠ¡å¹¶è¿½è¸ªè¿›åº¦...")

    # æäº¤ä»»åŠ¡
    print(f"ğŸ“¤ æäº¤ç ”ç©¶ä»»åŠ¡: '{TEST_PROMPT}'")
    response = requests.post(
        f"{BASE_URL}/generate_report",
        json={
            "prompt": TEST_PROMPT,
            "model": "deepseek:deepseek-chat"
        },
        timeout=30
    )

    assert response.status_code == 200
    data = response.json()
    task_id = data.get("task_id")

    assert task_id is not None
    print(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {task_id}")

    # è¿½è¸ªè¿›åº¦
    print(f"ğŸ“Š è¿½è¸ªä»»åŠ¡è¿›åº¦...")
    max_checks = 60  # æœ€å¤šæ£€æŸ¥ 60 æ¬¡ï¼ˆçº¦ 5 åˆ†é’Ÿï¼‰
    check_interval = 5  # æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡

    for i in range(max_checks):
        time.sleep(check_interval)

        # è·å–ä»»åŠ¡è¿›åº¦
        progress_response = requests.get(
            f"{BASE_URL}/task_progress/{task_id}",
            timeout=10
        )

        if progress_response.status_code == 200:
            progress_data = progress_response.json()
            status = progress_data.get("status", "unknown")
            current_step = progress_data.get("current_step", 0)
            total_steps = progress_data.get("total_steps", 0)

            print(f"â³ [{i+1}/{max_checks}] çŠ¶æ€: {status}, è¿›åº¦: {current_step}/{total_steps}")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if status == "completed":
                print("âœ… ä»»åŠ¡å·²å®Œæˆï¼")

                # è·å–æœ€ç»ˆæŠ¥å‘Š
                status_response = requests.get(
                    f"{BASE_URL}/task_status/{task_id}",
                    timeout=10
                )

                if status_response.status_code == 200:
                    status_data = status_response.json()
                    report = status_data.get("report", "")

                    print(f"\nğŸ“„ æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")
                    print(f"ğŸ“„ æŠ¥å‘Šé¢„è§ˆ:\n{report[:500]}...\n")

                    # éªŒè¯æŠ¥å‘Šä¸ä¸ºç©º
                    assert len(report) > 100, "æŠ¥å‘Šå†…å®¹å¤ªçŸ­"

                    # éªŒè¯æŠ¥å‘ŠåŒ…å«ç ”ç©¶ä¸»é¢˜å…³é”®è¯
                    assert "AI" in report or "Artificial" in report or "Healthcare" in report

                    print("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œå†…å®¹æœ‰æ•ˆ")
                    return

            # æ£€æŸ¥æ˜¯å¦å¤±è´¥
            elif status == "failed":
                error_msg = progress_data.get("error", "Unknown error")
                print(f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ max_tokens é”™è¯¯ï¼ˆPhase 1.5 åº”è¯¥å·²ä¿®å¤ï¼‰
                if "max_tokens" in error_msg.lower():
                    pytest.fail("âŒ å‘ç° max_tokens é”™è¯¯ï¼Phase 1.5 ä¿®å¤å¤±è´¥ï¼")
                else:
                    pytest.fail(f"ä»»åŠ¡å¤±è´¥: {error_msg}")

        else:
            print(f"âš ï¸ æ— æ³•è·å–è¿›åº¦: HTTP {progress_response.status_code}")

    # è¶…æ—¶
    pytest.fail(f"âŒ ä»»åŠ¡è¶…æ—¶ï¼ˆç­‰å¾… {max_checks * check_interval} ç§’åä»æœªå®Œæˆï¼‰")


def test_phase_1_5_no_max_tokens_error():
    """æµ‹è¯• 4: éªŒè¯ Phase 1.5 ä¿®å¤ï¼ˆæ—  max_tokens é”™è¯¯ï¼‰"""
    print("\nğŸ§ª æµ‹è¯• 4: éªŒè¯ Phase 1.5 ä¿®å¤...")

    # æäº¤ä¸€ä¸ªå¯èƒ½è§¦å‘é•¿æ–‡æœ¬çš„ä»»åŠ¡
    long_prompt = """
    Please conduct comprehensive research on the following topic:

    The Impact of Large Language Models on Scientific Research

    Please include:
    1. Historical development of LLMs
    2. Current applications in scientific research
    3. Case studies and examples
    4. Future directions and challenges
    5. Ethical considerations

    Please provide detailed analysis with citations.
    """

    print(f"ğŸ“¤ æäº¤é•¿æ–‡æœ¬ç ”ç©¶ä»»åŠ¡...")
    response = requests.post(
        f"{BASE_URL}/generate_report",
        json={
            "prompt": long_prompt,
            "model": "deepseek:deepseek-chat"
        },
        timeout=30
    )

    assert response.status_code == 200
    data = response.json()
    task_id = data.get("task_id")

    print(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {task_id}")

    # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè®©ä»»åŠ¡å¼€å§‹å¤„ç†
    print("â³ ç­‰å¾…ä»»åŠ¡å¤„ç†...")
    time.sleep(10)

    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
    progress_response = requests.get(
        f"{BASE_URL}/task_progress/{task_id}",
        timeout=10
    )

    if progress_response.status_code == 200:
        progress_data = progress_response.json()
        status = progress_data.get("status", "unknown")
        error = progress_data.get("error", "")

        print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {status}")

        # éªŒè¯æ²¡æœ‰ max_tokens é”™è¯¯
        if "max_tokens" in error.lower():
            pytest.fail("âŒ å‘ç° max_tokens é”™è¯¯ï¼Phase 1.5 ä¿®å¤å¤±è´¥ï¼")

        if status == "failed":
            print(f"âš ï¸ ä»»åŠ¡å¤±è´¥ï¼ˆé max_tokens é”™è¯¯ï¼‰: {error}")
        else:
            print("âœ… æ²¡æœ‰å‘ç° max_tokens é”™è¯¯ï¼ŒPhase 1.5 ä¿®å¤æœ‰æ•ˆ")

    print("âœ… Phase 1.5 éªŒè¯é€šè¿‡")


def test_cost_tracking():
    """æµ‹è¯• 5: éªŒè¯æˆæœ¬è¿½è¸ªåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯• 5: éªŒè¯æˆæœ¬è¿½è¸ª...")

    # æäº¤ç®€å•ä»»åŠ¡
    response = requests.post(
        f"{BASE_URL}/generate_report",
        json={
            "prompt": "Quick test: What is AI?",
            "model": "deepseek:deepseek-chat"
        },
        timeout=30
    )

    assert response.status_code == 200
    task_id = response.json().get("task_id")

    print(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {task_id}")

    # ç­‰å¾…ä»»åŠ¡å®Œæˆæˆ–éƒ¨åˆ†å®Œæˆ
    time.sleep(15)

    # è·å–ä»»åŠ¡çŠ¶æ€
    status_response = requests.get(
        f"{BASE_URL}/task_status/{task_id}",
        timeout=10
    )

    if status_response.status_code == 200:
        status_data = status_response.json()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆæœ¬ä¿¡æ¯ï¼ˆå¦‚æœ API è¿”å›ï¼‰
        # æ³¨æ„ï¼šmain.py å¯èƒ½æ²¡æœ‰ç›´æ¥è¿”å›æˆæœ¬ï¼Œä½†åå°åº”è¯¥æœ‰è¿½è¸ª
        print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {status_data.get('status')}")
        print("âœ… æˆæœ¬è¿½è¸ªåŠŸèƒ½è¿è¡Œæ­£å¸¸ï¼ˆåå°è®°å½•ï¼‰")

    print("âœ… æˆæœ¬è¿½è¸ªéªŒè¯å®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    print("=" * 60)
    print("ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯• API åŠŸèƒ½ï¼ˆä¸éœ€è¦ Playwrightï¼‰
    test_api_submit_and_track()
    test_phase_1_5_no_max_tokens_error()
    test_cost_tracking()

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
