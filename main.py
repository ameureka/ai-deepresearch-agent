"""
ä¸»åº”ç”¨ç¨‹åº - å¤šä»£ç†ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿçš„ Web æœåŠ¡
æœ¬æ–‡ä»¶å®ç°äº†ä¸€ä¸ª FastAPI Web åº”ç”¨ï¼Œæä¾›ï¼š
1. ç”¨æˆ·ç•Œé¢ç”¨äºæäº¤ç ”ç©¶ä¸»é¢˜
2. åå°ä»»åŠ¡å¤„ç†ç³»ç»Ÿ
3. å®æ—¶è¿›åº¦è·Ÿè¸ª
4. æ•°æ®åº“æŒä¹…åŒ–
5. Phase 2: æ ‡å‡†åŒ– API å’Œ SSE æµå¼æ¥å£
"""

import os
import uuid
import json
import threading
import logging
import traceback
from datetime import datetime
from typing import Optional, Literal
from fastapi import FastAPI, HTTPException, Request, status
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ValidationError
from sqlalchemy import create_engine, Column, Text, DateTime, String
from sqlalchemy.orm import sessionmaker, declarative_base
from dotenv import load_dotenv

from src.planning_agent import planner_agent, executor_agent_step
from src.api_models import ApiResponse, ResearchRequest, HealthResponse, ModelInfo
from src.sse import (
    format_sse_event,
    SSEEvents,
    get_sse_headers,
    create_start_event,
    create_plan_event,
    create_progress_event,
    create_done_event,
    create_error_event
)
from fastapi.responses import StreamingResponse

import html, textwrap

# === é…ç½®ç»“æ„åŒ–æ—¥å¿— ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# === åŠ è½½ç¯å¢ƒå˜é‡ ===
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")

# ä¿®å¤ Heroku çš„ postgres:// URL æ ¼å¼ï¼ˆéœ€è¦ä½¿ç”¨ postgresql://ï¼‰
if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

if not DATABASE_URL:
    raise RuntimeError("DATABASE_URL æœªè®¾ç½®")


# === æ•°æ®åº“è®¾ç½® ===
Base = declarative_base()
engine = create_engine(DATABASE_URL, echo=False, future=True)
SessionLocal = sessionmaker(bind=engine)


class Task(Base):
    """
    ä»»åŠ¡æ•°æ®æ¨¡å‹ - å­˜å‚¨ç ”ç©¶æŠ¥å‘Šç”Ÿæˆä»»åŠ¡çš„ä¿¡æ¯
    """

    __tablename__ = "tasks"
    id = Column(String, primary_key=True, index=True)  # ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
    prompt = Column(Text)  # ç”¨æˆ·è¾“å…¥çš„ç ”ç©¶ä¸»é¢˜
    status = Column(String)  # ä»»åŠ¡çŠ¶æ€ï¼šrunning, done, error
    created_at = Column(DateTime, default=datetime.utcnow)  # åˆ›å»ºæ—¶é—´
    updated_at = Column(DateTime, default=datetime.utcnow)  # æ›´æ–°æ—¶é—´
    result = Column(Text)  # ä»»åŠ¡ç»“æœï¼ˆJSON æ ¼å¼ï¼‰


# åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
try:
    Base.metadata.create_all(bind=engine)
    logger.info("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    logger.error(f"âŒ æ•°æ®åº“åˆ›å»ºå¤±è´¥: {e}")
    raise RuntimeError(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

# === FastAPI åº”ç”¨è®¾ç½® ===
app = FastAPI(
    title="AI Research Assistant API",
    description="å¤šä»£ç†ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ - Phase 2 æ ‡å‡†åŒ– API",
    version="2.0.0"
)

# === Phase 2: é…ç½® CORS ä¸­é—´ä»¶ï¼ˆæ›´ä¸¥æ ¼çš„é…ç½®ï¼‰===
# ä»ç¯å¢ƒå˜é‡è¯»å–å…è®¸çš„æ¥æºï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
ALLOWED_ORIGINS = os.getenv(
    "ALLOWED_ORIGINS",
    "http://localhost:3000,https://*.vercel.app"
).split(",")

# å¤„ç†é€šé…ç¬¦åŸŸåï¼ˆ*.vercel.appï¼‰
# FastAPI çš„ CORSMiddleware æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

logger.info(f"âœ… CORS é…ç½®å®Œæˆï¼Œå…è®¸çš„æ¥æº: {ALLOWED_ORIGINS}")

# === Phase 2: å…¨å±€å¼‚å¸¸å¤„ç†å™¨ ===
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """
    å…¨å±€å¼‚å¸¸å¤„ç†å™¨ - æ•è·æ‰€æœ‰æœªå¤„ç†çš„å¼‚å¸¸

    è¿™ç¡®ä¿ï¼š
    1. æ‰€æœ‰é”™è¯¯éƒ½è¿”å›ç»Ÿä¸€çš„ ApiResponse æ ¼å¼
    2. ä¸å‘å®¢æˆ·ç«¯æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚å †æ ˆè·Ÿè¸ªï¼‰
    3. é”™è¯¯è¢«æ­£ç¡®è®°å½•åˆ°æ—¥å¿—ç³»ç»Ÿ

    å‚æ•°ï¼š
        request: FastAPI è¯·æ±‚å¯¹è±¡
        exc: æ•è·çš„å¼‚å¸¸

    è¿”å›ï¼š
        JSONResponse with ApiResponse format
    """
    # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—ï¼ˆåŒ…å«å †æ ˆè·Ÿè¸ªï¼‰
    logger.error(
        f"âŒ æœªå¤„ç†çš„å¼‚å¸¸: {type(exc).__name__}: {str(exc)}\n"
        f"è·¯å¾„: {request.url.path}\n"
        f"æ–¹æ³•: {request.method}\n"
        f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}"
    )

    # å‘å®¢æˆ·ç«¯è¿”å›ç®€åŒ–çš„é”™è¯¯ä¿¡æ¯ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content=ApiResponse(
            success=False,
            error=f"Internal server error: {type(exc).__name__}"
        ).dict()
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """
    HTTP å¼‚å¸¸å¤„ç†å™¨ - å¤„ç†æ ‡å‡†çš„ HTTP å¼‚å¸¸

    å°† FastAPI çš„ HTTPException è½¬æ¢ä¸ºæ ‡å‡†çš„ ApiResponse æ ¼å¼ã€‚

    å‚æ•°ï¼š
        request: FastAPI è¯·æ±‚å¯¹è±¡
        exc: HTTPException å®ä¾‹

    è¿”å›ï¼š
        JSONResponse with ApiResponse format
    """
    logger.warning(
        f"âš ï¸ HTTP å¼‚å¸¸ {exc.status_code}: {exc.detail}\n"
        f"è·¯å¾„: {request.url.path}\n"
        f"æ–¹æ³•: {request.method}"
    )

    return JSONResponse(
        status_code=exc.status_code,
        content=ApiResponse(
            success=False,
            error=exc.detail
        ).dict()
    )


@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    """
    Pydantic éªŒè¯å¼‚å¸¸å¤„ç†å™¨

    å¤„ç†è¯·æ±‚ä½“éªŒè¯å¤±è´¥çš„æƒ…å†µã€‚

    å‚æ•°ï¼š
        request: FastAPI è¯·æ±‚å¯¹è±¡
        exc: ValidationError å®ä¾‹

    è¿”å›ï¼š
        JSONResponse with ApiResponse format
    """
    logger.warning(
        f"âš ï¸ è¯·æ±‚éªŒè¯å¤±è´¥:\n"
        f"è·¯å¾„: {request.url.path}\n"
        f"é”™è¯¯: {exc.errors()}"
    )

    # æ ¼å¼åŒ–éªŒè¯é”™è¯¯ä¿¡æ¯
    error_messages = []
    for error in exc.errors():
        field = " -> ".join(str(loc) for loc in error["loc"])
        message = error["msg"]
        error_messages.append(f"{field}: {message}")

    return JSONResponse(
        status_code=status.HTTP_400_BAD_REQUEST,
        content=ApiResponse(
            success=False,
            error=f"Validation error: {'; '.join(error_messages)}"
        ).dict()
    )


# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory="static"), name="static")
# è®¾ç½®æ¨¡æ¿å¼•æ“
templates = Jinja2Templates(directory="templates")

# å†…å­˜ä¸­çš„ä»»åŠ¡è¿›åº¦è·Ÿè¸ªå­—å…¸
task_progress = {}


class PromptRequest(BaseModel):
    """è¯·æ±‚æ¨¡å‹ - ç”¨æˆ·æäº¤çš„ç ”ç©¶ä¸»é¢˜"""

    prompt: str


@app.get("/", response_class=HTMLResponse)
def read_index(request: Request):
    """
    é¦–é¡µè·¯ç”± - è¿”å›ä¸»ç•Œé¢ HTML
    """
    return templates.TemplateResponse("index.html", {"request": request})


@app.get("/api", response_class=JSONResponse)
def health_check(request: Request):
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹ - ç”¨äºéªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ

    ã€å·²å¼ƒç”¨ã€‘æ­¤ç«¯ç‚¹ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œè¯·ä½¿ç”¨ /api/health
    """
    return {"status": "ok"}


# === Phase 2: æ ‡å‡†åŒ– API æ¥å£ ===

@app.get("/api/health", response_model=ApiResponse)
async def health_check_v2():
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆPhase 2 æ ‡å‡†åŒ–ç‰ˆæœ¬ï¼‰

    è¿”å›æœåŠ¡çŠ¶æ€ä¿¡æ¯ï¼Œç”¨äºï¼š
    1. ç›‘æ§æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
    2. é˜²æ­¢æœåŠ¡ä¼‘çœ ï¼ˆcron-job.org å®šæœŸ pingï¼‰
    3. è´Ÿè½½å‡è¡¡å™¨å¥åº·æ£€æŸ¥

    æ€§èƒ½è¦æ±‚ï¼š< 100ms

    è¿”å›ï¼š
        ApiResponse with HealthResponse data
        - status: "ok" | "degraded" | "error"
        - timestamp: ISO æ ¼å¼æ—¶é—´æˆ³
        - version: API ç‰ˆæœ¬å·

    çŠ¶æ€ç ï¼š
        200: æœåŠ¡æ­£å¸¸
        503: æœåŠ¡ä¸å¯ç”¨ï¼ˆä½†è¿›ç¨‹ä»åœ¨è¿è¡Œï¼‰
    """
    import time
    start_time = time.time()

    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥ï¼ˆå¯é€‰ï¼‰
        # å¦‚æœæ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œä»ç„¶è¿”å› 200ï¼Œä½† status ä¸º "degraded"
        db_ok = True
        try:
            db = SessionLocal()
            db.execute("SELECT 1")
            db.close()
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            db_ok = False

        # è®¡ç®—å“åº”æ—¶é—´
        elapsed_ms = (time.time() - start_time) * 1000

        # æ„å»ºå“åº”
        health_data = HealthResponse(
            status="ok" if db_ok else "degraded",
            timestamp=datetime.utcnow().isoformat() + "Z",
            version="2.0.0"
        )

        logger.info(f"âœ… å¥åº·æ£€æŸ¥æˆåŠŸ ({elapsed_ms:.1f}ms)")

        return ApiResponse(
            success=True,
            data=health_data.dict()
        )

    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return JSONResponse(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            content=ApiResponse(
                success=False,
                error="Service temporarily unavailable"
            ).dict()
        )


@app.get("/api/models", response_model=ApiResponse)
async def get_models():
    """
    è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

    è¿”å›ç³»ç»Ÿä¸­é…ç½®çš„æ‰€æœ‰ AI æ¨¡å‹ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - æ¨¡å‹åç§°å’Œæ ‡è¯†ç¬¦
    - æä¾›å•†ä¿¡æ¯
    - ä¸Šä¸‹æ–‡çª—å£å¤§å°
    - æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º

    è¿™ä¸ªæ¥å£ï¼š
    1. ç”¨äºå‰ç«¯å±•ç¤ºå¯ç”¨æ¨¡å‹
    2. å¸®åŠ©ç”¨æˆ·äº†è§£ç³»ç»Ÿèƒ½åŠ›
    3. æ”¯æŒåŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰

    æ€§èƒ½è¦æ±‚ï¼š< 200msï¼ˆé™æ€æ•°æ®ï¼‰

    è¿”å›ï¼š
        ApiResponse with list of ModelInfo

    ç¤ºä¾‹å“åº”ï¼š
        {
            "success": true,
            "data": {
                "models": [
                    {
                        "name": "deepseek:deepseek-chat",
                        "provider": "deepseek",
                        "description": "DeepSeek Chat - é«˜æ€§ä»·æ¯”é€šç”¨å¯¹è¯æ¨¡å‹",
                        "context_window": 65536,
                        "supports_streaming": true
                    },
                    ...
                ]
            }
        }
    """
    from src.config import ModelConfig

    try:
        # æ„å»ºæ¨¡å‹ä¿¡æ¯åˆ—è¡¨
        models = [
            ModelInfo(
                name=ModelConfig.PLANNER_MODEL,
                provider=ModelConfig.PLANNER_MODEL.split(":")[0],
                description="DeepSeek Reasoner - å¤æ‚æ¨ç†å’Œè§„åˆ’ä»»åŠ¡ä¸“ç”¨æ¨¡å‹",
                context_window=65536,
                supports_streaming=True
            ),
            ModelInfo(
                name=ModelConfig.RESEARCHER_MODEL,
                provider=ModelConfig.RESEARCHER_MODEL.split(":")[0],
                description="DeepSeek Chat - ç ”ç©¶å’Œä¿¡æ¯æœé›†",
                context_window=65536,
                supports_streaming=True
            ),
            ModelInfo(
                name=ModelConfig.WRITER_MODEL,
                provider=ModelConfig.WRITER_MODEL.split(":")[0],
                description="DeepSeek Chat - å†…å®¹ç”Ÿæˆå’Œå†™ä½œ",
                context_window=65536,
                supports_streaming=True
            ),
            ModelInfo(
                name=ModelConfig.EDITOR_MODEL,
                provider=ModelConfig.EDITOR_MODEL.split(":")[0],
                description="DeepSeek Chat - å†…å®¹å®¡æ ¸å’Œç¼–è¾‘",
                context_window=65536,
                supports_streaming=True
            ),
            ModelInfo(
                name=ModelConfig.FALLBACK_MODEL,
                provider=ModelConfig.FALLBACK_MODEL.split(":")[0],
                description="GPT-4O Mini - é«˜å¯é æ€§é™çº§æ¨¡å‹",
                context_window=128000,
                supports_streaming=True
            ),
        ]

        # å»é‡ï¼ˆç›¸åŒçš„æ¨¡å‹å¯èƒ½è¢«å¤šä¸ª agent ä½¿ç”¨ï¼‰
        unique_models = {}
        for model in models:
            if model.name not in unique_models:
                unique_models[model.name] = model

        logger.info(f"ğŸ“‹ è¿”å› {len(unique_models)} ä¸ªæ¨¡å‹ä¿¡æ¯")

        return ApiResponse(
            success=True,
            data={
                "models": [m.dict() for m in unique_models.values()],
                "total": len(unique_models),
                "default_model": ModelConfig.RESEARCHER_MODEL
            }
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve models: {str(e)}"
        )


@app.post("/generate_report")
def generate_report(req: PromptRequest):
    """
    ç”ŸæˆæŠ¥å‘Šç«¯ç‚¹ - æ¥æ”¶ç”¨æˆ·çš„ç ”ç©¶ä¸»é¢˜å¹¶å¯åŠ¨åå°ä»»åŠ¡
    
    å‚æ•°:
        req: åŒ…å«ç ”ç©¶ä¸»é¢˜çš„è¯·æ±‚å¯¹è±¡
    
    è¿”å›:
        åŒ…å«ä»»åŠ¡ ID çš„å­—å…¸
    """
    # ç”Ÿæˆå”¯ä¸€çš„ä»»åŠ¡ ID
    task_id = str(uuid.uuid4())
    
    # åœ¨æ•°æ®åº“ä¸­åˆ›å»ºä»»åŠ¡è®°å½•
    db = SessionLocal()
    db.add(Task(id=task_id, prompt=req.prompt, status="running"))
    db.commit()
    db.close()

    # åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦è·Ÿè¸ª
    task_progress[task_id] = {"steps": []}
    
    # ä½¿ç”¨è§„åˆ’ä»£ç†ç”Ÿæˆæ‰§è¡Œæ­¥éª¤
    initial_plan_steps = planner_agent(req.prompt)
    
    # ä¸ºæ¯ä¸ªæ­¥éª¤åˆ›å»ºè¿›åº¦è·Ÿè¸ªæ¡ç›®
    for step_title in initial_plan_steps:
        task_progress[task_id]["steps"].append(
            {
                "title": step_title,
                "status": "pending",  # å¾…æ‰§è¡Œ
                "description": "ç­‰å¾…æ‰§è¡Œ",
                "substeps": [],
            }
        )

    # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ä»£ç†å·¥ä½œæµ
    thread = threading.Thread(
        target=run_agent_workflow, args=(task_id, req.prompt, initial_plan_steps)
    )
    thread.start()
    return {"task_id": task_id}


@app.get("/task_progress/{task_id}")
def get_task_progress(task_id: str):
    """
    è·å–ä»»åŠ¡è¿›åº¦ç«¯ç‚¹ - è¿”å›ä»»åŠ¡çš„å®æ—¶æ‰§è¡Œè¿›åº¦
    
    å‚æ•°:
        task_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
    
    è¿”å›:
        åŒ…å«æ­¥éª¤åˆ—è¡¨çš„è¿›åº¦ä¿¡æ¯
    """
    return task_progress.get(task_id, {"steps": []})


@app.get("/task_status/{task_id}")
def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€ç«¯ç‚¹ - è¿”å›ä»»åŠ¡çš„æœ€ç»ˆçŠ¶æ€å’Œç»“æœ
    
    å‚æ•°:
        task_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
    
    è¿”å›:
        åŒ…å«ä»»åŠ¡çŠ¶æ€å’Œç»“æœçš„å­—å…¸
    """
    db = SessionLocal()
    task = db.query(Task).filter(Task.id == task_id).first()
    db.close()
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
    return {
        "status": task.status,
        "result": json.loads(task.result) if task.result else None,
    }


def format_history(history):
    """
    æ ¼å¼åŒ–æ‰§è¡Œå†å² - å°†å†å²è®°å½•è½¬æ¢ä¸ºå¯è¯»çš„å­—ç¬¦ä¸²æ ¼å¼
    
    å‚æ•°:
        history: æ‰§è¡Œå†å²åˆ—è¡¨ [(æ ‡é¢˜, æè¿°, è¾“å‡º), ...]
    
    è¿”å›:
        æ ¼å¼åŒ–çš„å†å²å­—ç¬¦ä¸²
    """
    return "\n\n".join(
        f"ğŸ”¹ {title}\n{desc}\n\nğŸ“ è¾“å‡º:\n{output}" for title, desc, output in history
    )


def run_agent_workflow(task_id: str, prompt: str, initial_plan_steps: list):
    """
    è¿è¡Œä»£ç†å·¥ä½œæµ - åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå¤šä»£ç†ç ”ç©¶ä»»åŠ¡
    
    å‚æ•°:
        task_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
        prompt: ç”¨æˆ·çš„ç ”ç©¶ä¸»é¢˜
        initial_plan_steps: è§„åˆ’ä»£ç†ç”Ÿæˆçš„æ‰§è¡Œæ­¥éª¤åˆ—è¡¨
    """
    steps_data = task_progress[task_id]["steps"]
    execution_history = []

    def update_step_status(index, status, description="", substep=None):
        """
        æ›´æ–°æ­¥éª¤çŠ¶æ€ - æ›´æ–°ä»»åŠ¡è¿›åº¦è·Ÿè¸ªä¸­çš„æ­¥éª¤ä¿¡æ¯
        
        å‚æ•°:
            index: æ­¥éª¤ç´¢å¼•
            status: æ–°çŠ¶æ€ï¼ˆpending, running, done, errorï¼‰
            description: çŠ¶æ€æè¿°
            substep: å­æ­¥éª¤ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        if index < len(steps_data):
            steps_data[index]["status"] = status
            if description:
                steps_data[index]["description"] = description
            if substep:
                steps_data[index]["substeps"].append(substep)
            steps_data[index]["updated_at"] = datetime.utcnow().isoformat()

    try:
        # éå†å¹¶æ‰§è¡Œæ¯ä¸ªè®¡åˆ’æ­¥éª¤
        for i, plan_step_title in enumerate(initial_plan_steps):
            update_step_status(i, "running", f"æ­£åœ¨æ‰§è¡Œ: {plan_step_title}")

            # æ‰§è¡Œå•ä¸ªä»£ç†æ­¥éª¤
            actual_step_description, agent_name, output = executor_agent_step(
                plan_step_title, execution_history, prompt
            )

            # å°†æ‰§è¡Œç»“æœæ·»åŠ åˆ°å†å²è®°å½•
            execution_history.append([plan_step_title, actual_step_description, output])

            # HTML è½¬ä¹‰å‡½æ•°
            def esc(s: str) -> str:
                return html.escape(s or "")

            def nl2br(s: str) -> str:
                return esc(s).replace("\n", "<br>")

            # æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸ºå®Œæˆï¼Œå¹¶æ·»åŠ è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯
            update_step_status(
                i,
                "done",
                f"å·²å®Œæˆ: {plan_step_title}",
                {
                    "title": f"è°ƒç”¨äº† {agent_name}",
                    "content": f"""
<div style='border:1px solid #ccc; border-radius:8px; padding:10px; margin:8px 0; background:#fff;'>
  <div style='font-weight:bold; color:#2563eb;'>ğŸ“˜ ç”¨æˆ·æç¤º</div>
  <div style='white-space:pre-wrap;'>{prompt}</div>

  <div style='font-weight:bold; color:#16a34a; margin-top:8px;'>ğŸ“œ ä¸Šä¸€æ­¥</div>
  <pre style='white-space:pre-wrap; background:#f9fafb; padding:6px; border-radius:6px; margin:0;'>
{format_history(execution_history[-2:-1])}
  </pre>

  <div style='font-weight:bold; color:#f59e0b; margin-top:8px;'>ğŸ§¹ å½“å‰ä»»åŠ¡</div>
  <div style='white-space:pre-wrap;'>{actual_step_description}</div>

  <div style='font-weight:bold; color:#10b981; margin-top:8px;'>âœ… è¾“å‡º</div>
  <!-- âš ï¸ è¿™é‡Œä¸ä½¿ç”¨ <pre> æ ‡ç­¾ä»¥ä¿ç•™ HTML æ ¼å¼ -->
  <div style='white-space:pre-wrap;'>
{output}
  </div>
</div>
""".strip(),
                },
            )

        # æå–æœ€ç»ˆæŠ¥å‘Šï¼ˆæœ€åä¸€æ­¥çš„è¾“å‡ºï¼‰
        final_report_markdown = (
            execution_history[-1][-1] if execution_history else "æœªç”ŸæˆæŠ¥å‘Šã€‚"
        )

        # æ„å»ºç»“æœå¯¹è±¡
        result = {"html_report": final_report_markdown, "history": steps_data}

        # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€
        db = SessionLocal()
        task = db.query(Task).filter(Task.id == task_id).first()
        task.status = "done"
        task.result = json.dumps(result)
        task.updated_at = datetime.utcnow()
        db.commit()
        db.close()

    except Exception as e:
        # å¤„ç†å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­çš„é”™è¯¯
        print(f"ä»»åŠ¡ {task_id} çš„å·¥ä½œæµé”™è¯¯: {e}")
        
        # æ‰¾åˆ°å‡ºé”™çš„æ­¥éª¤å¹¶æ›´æ–°å…¶çŠ¶æ€
        if steps_data:
            error_step_index = next(
                (i for i, s in enumerate(steps_data) if s["status"] == "running"),
                len(steps_data) - 1,
            )
            if error_step_index >= 0:
                update_step_status(
                    error_step_index,
                    "error",
                    f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}",
                    {"title": "é”™è¯¯", "content": str(e)},
                )

        # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€ä¸ºé”™è¯¯
        db = SessionLocal()
        task = db.query(Task).filter(Task.id == task_id).first()
        task.status = "error"
        task.updated_at = datetime.utcnow()
        db.commit()
        db.close()


# === Phase 2: SSE æµå¼æ¥å£ ===

@app.post("/api/research/stream")
async def research_stream(request: ResearchRequest):
    """
    SSE æµå¼ç ”ç©¶æ¥å£ï¼ˆPhase 2 æ ¸å¿ƒåŠŸèƒ½ï¼‰

    æ¥æ”¶ç ”ç©¶ä¸»é¢˜ï¼Œé€šè¿‡ Server-Sent Events (SSE) å®æ—¶æ¨é€ç ”ç©¶è¿›åº¦å’Œç»“æœã€‚

    å·¥ä½œæµç¨‹ï¼š
        1. å‘é€ START äº‹ä»¶ï¼ˆåŒ…å« promptï¼‰
        2. è°ƒç”¨ planner_agent ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        3. å‘é€ PLAN äº‹ä»¶ï¼ˆåŒ…å«æ­¥éª¤åˆ—è¡¨ï¼‰
        4. å¾ªç¯æ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼š
           a. å‘é€ PROGRESS äº‹ä»¶ï¼ˆæ­¥éª¤ç¼–å·ã€æ€»æ•°ã€æè¿°ï¼‰
           b. è°ƒç”¨ executor_agent_step æ‰§è¡Œæ­¥éª¤
        5. å‘é€ DONE äº‹ä»¶ï¼ˆåŒ…å«æœ€ç»ˆæŠ¥å‘Šï¼‰
        6. å¦‚æœå‡ºé”™ï¼Œå‘é€ ERROR äº‹ä»¶

    SSE äº‹ä»¶ç±»å‹ï¼š
        - start: ä»»åŠ¡å¼€å§‹ï¼Œdata: {prompt}
        - plan: æ‰§è¡Œè®¡åˆ’ï¼Œdata: {steps: [str]}
        - progress: æ­¥éª¤è¿›åº¦ï¼Œdata: {step, total, message}
        - done: ä»»åŠ¡å®Œæˆï¼Œdata: {report: str}
        - error: å‘ç”Ÿé”™è¯¯ï¼Œdata: {message, step?}

    å‚æ•°ï¼š
        request: ResearchRequest
            - prompt: ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼Œ10-5000 å­—ç¬¦ï¼‰
            - model: å¯é€‰çš„æ¨¡å‹åç§°

    è¿”å›ï¼š
        StreamingResponse (text/event-stream)

    å“åº”å¤´ï¼š
        - Content-Type: text/event-stream
        - Cache-Control: no-cache, no-transform
        - Connection: keep-alive
        - X-Accel-Buffering: no (ç¦ç”¨ Nginx ç¼“å†²)

    æ€§èƒ½è¦æ±‚ï¼š
        - é¦–ä¸ªäº‹ä»¶ (START) < 2s
        - å®Œæ•´ä»»åŠ¡ < 5min
        - æ”¯æŒ 5 ä¸ªå¹¶å‘è¿æ¥

    é”™è¯¯å¤„ç†ï¼š
        - æ‰€æœ‰å¼‚å¸¸éƒ½ä¼šå‘é€ ERROR äº‹ä»¶
        - ä¸ä¼šä¸­æ–­è¿æ¥ï¼ˆå®¢æˆ·ç«¯å†³å®šä½•æ—¶å…³é—­ï¼‰
        - è¯¦ç»†é”™è¯¯è®°å½•åˆ°æ—¥å¿—

    ä½¿ç”¨ç¤ºä¾‹ï¼ˆcurlï¼‰ï¼š
        curl -X POST http://localhost:8000/api/research/stream \\
             -H "Content-Type: application/json" \\
             -d '{"prompt": "Research AI applications"}' \\
             -N

    ä½¿ç”¨ç¤ºä¾‹ï¼ˆJavaScriptï¼‰ï¼š
        const eventSource = new EventSource('/api/research/stream');
        eventSource.addEventListener('start', (e) => {
            const data = JSON.parse(e.data);
            console.log('Started:', data.prompt);
        });
        eventSource.addEventListener('progress', (e) => {
            const data = JSON.parse(e.data);
            console.log(`Step ${data.step}/${data.total}: ${data.message}`);
        });
        eventSource.addEventListener('done', (e) => {
            const data = JSON.parse(e.data);
            console.log('Report:', data.report);
            eventSource.close();
        });

    è®¾è®¡å†³ç­–ï¼š
        - ä¸ä½¿ç”¨æ•°æ®åº“ï¼ˆå‡å°‘å»¶è¿Ÿï¼Œç¬¦åˆ MVP åŸåˆ™ï¼‰
        - ä¸ä¿å­˜å†å²ï¼ˆå®¢æˆ·ç«¯è´Ÿè´£è®°å½•ï¼‰
        - ä½¿ç”¨å¼‚æ­¥ç”Ÿæˆå™¨ï¼ˆasync generatorï¼‰
        - é”™è¯¯æ—¶ä¸å…³é—­è¿æ¥ï¼ˆå®¢æˆ·ç«¯æ§åˆ¶ï¼‰
    """
    logger.info(f"ğŸš€ SSE æµå¼ç ”ç©¶è¯·æ±‚: {request.prompt[:50]}...")

    async def event_generator():
        """
        å¼‚æ­¥äº‹ä»¶ç”Ÿæˆå™¨

        ä½¿ç”¨ async generator é€æ­¥ç”Ÿæˆ SSE äº‹ä»¶ã€‚
        è¿™å…è®¸ï¼š
        1. éé˜»å¡æ‰§è¡Œ
        2. å®æ—¶æ¨é€äº‹ä»¶
        3. è‡ªåŠ¨æ¸…ç†èµ„æº
        """
        try:
            # === 1. START äº‹ä»¶ ===
            logger.info("ğŸ“¤ å‘é€ START äº‹ä»¶")
            yield create_start_event(request.prompt)

            # === 2. PLAN äº‹ä»¶ - è°ƒç”¨ planner_agent ===
            logger.info("ğŸ§  è°ƒç”¨ planner_agent ç”Ÿæˆæ‰§è¡Œè®¡åˆ’")
            try:
                # planner_agent è¿”å› List[str] (æ­¥éª¤åˆ—è¡¨)
                steps = planner_agent(
                    request.prompt,
                    model=request.model  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
                )
                logger.info(f"âœ… ç”Ÿæˆäº† {len(steps)} ä¸ªæ‰§è¡Œæ­¥éª¤")
            except Exception as e:
                logger.error(f"âŒ planner_agent å¤±è´¥: {e}")
                # å¦‚æœè§„åˆ’å¤±è´¥ï¼Œå‘é€é”™è¯¯äº‹ä»¶å¹¶ç»ˆæ­¢
                yield create_error_event(f"Failed to generate plan: {str(e)}")
                return

            # å‘é€ PLAN äº‹ä»¶
            logger.info("ğŸ“¤ å‘é€ PLAN äº‹ä»¶")
            yield create_plan_event(steps)

            # === 3. æ‰§è¡Œæ­¥éª¤å¾ªç¯ ===
            execution_history = []

            for i, step_title in enumerate(steps):
                # å‘é€ PROGRESS äº‹ä»¶
                step_number = i + 1
                logger.info(f"ğŸ“¤ å‘é€ PROGRESS äº‹ä»¶: {step_number}/{len(steps)}")
                yield create_progress_event(
                    step=step_number,
                    total=len(steps),
                    message=step_title
                )

                # æ‰§è¡Œæ­¥éª¤
                logger.info(f"âš™ï¸  æ‰§è¡Œæ­¥éª¤ {step_number}: {step_title[:50]}...")
                try:
                    # executor_agent_step è¿”å›: (step_description, agent_name, output)
                    step_desc, agent_name, output = executor_agent_step(
                        step_title,
                        execution_history,
                        request.prompt,
                        model=request.model  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
                    )

                    # æ·»åŠ åˆ°å†å²è®°å½•
                    execution_history.append([step_title, step_desc, output])

                    logger.info(
                        f"âœ… æ­¥éª¤ {step_number} å®Œæˆï¼Œ"
                        f"ä½¿ç”¨ä»£ç†: {agent_name}ï¼Œ"
                        f"è¾“å‡ºé•¿åº¦: {len(output)} å­—ç¬¦"
                    )

                except Exception as e:
                    # æ­¥éª¤æ‰§è¡Œå¤±è´¥
                    logger.error(f"âŒ æ­¥éª¤ {step_number} æ‰§è¡Œå¤±è´¥: {e}")
                    yield create_error_event(
                        message=f"Step {step_number} failed: {str(e)}",
                        step=step_number
                    )
                    # æ³¨æ„ï¼šç»§ç»­æ‰§è¡Œè¿˜æ˜¯ç»ˆæ­¢ï¼Ÿè¿™é‡Œé€‰æ‹©ç»ˆæ­¢
                    # å¦‚æœè¦ç»§ç»­æ‰§è¡Œï¼Œå»æ‰ return è¯­å¥
                    return

            # === 4. DONE äº‹ä»¶ - å‘é€æœ€ç»ˆæŠ¥å‘Š ===
            if execution_history:
                # æœ€åä¸€æ­¥çš„è¾“å‡ºå°±æ˜¯æœ€ç»ˆæŠ¥å‘Š
                final_report = execution_history[-1][2]  # [step_title, step_desc, output]
                logger.info(f"ğŸ“¤ å‘é€ DONE äº‹ä»¶ï¼ŒæŠ¥å‘Šé•¿åº¦: {len(final_report)} å­—ç¬¦")
                yield create_done_event(final_report)
            else:
                # æ²¡æœ‰å†å²è®°å½•ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                logger.warning("âš ï¸ æ‰§è¡Œå†å²ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                yield create_error_event("No report generated")

        except Exception as e:
            # === 5. ERROR äº‹ä»¶ - æ•è·æ‰€æœ‰æœªå¤„ç†çš„å¼‚å¸¸ ===
            logger.error(f"âŒ SSE ç”Ÿæˆå™¨å‘ç”Ÿæœªå¤„ç†çš„å¼‚å¸¸: {e}\n{traceback.format_exc()}")
            yield create_error_event(f"Internal error: {str(e)}")

    # è¿”å› StreamingResponse
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers=get_sse_headers()
    )
